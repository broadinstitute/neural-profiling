tart training on 14383844
-------------
{
    "dataset": {
        "metadata": {
            "label_field": "Compound",
            "control_value": "DMSO"
        },
        "images": {
            "channels": [
                "DNA",
                "RNA",
                "ER",
                "AGP",
                "Mito"
              ],
            "file_format": "png",
            "bits": 8,
            "width": 1080,
            "height": 1080
        },
        "locations":{
            "mode": "single_cells",
            "box_size": 128,
            "area_coverage": 0.75,
            "mask_objects": false
        }
    },
    "prepare": {
        "illumination_correction": {
            "down_scale_factor": 4,
            "median_filter_size": 24
        },
        "compression": {
            "implement": false,
            "scaling_factor": 1.0
        }
    },
    "train": {
        "partition": {
            "targets": [
                "Compound"
            ],
            "split_field": "Split",
            "training": ["Training"],
            "validation": ["Validation"]
        },
        "model": {
            "name": "efficientnet",
            "augmentations": true,
            "crop_generator": "sampled_crop_generator",
            "metrics": ["accuracy", "top_k"],
            "epochs": 30,
            "initialization":"ImageNet",
            "params": {
                "learning_rate": 0.04,
                "batch_size": 64,
                "conv_blocks": 0,
                "label_smoothing": 0.00,
                "feature_dim": 256,
                "pooling": "avg"
            },
            "lr_schedule": "cosine"
        },
        "sampling": {
            "factor": 1,
            "workers": 4,
            "cache_size": 10000
        },
        "validation": {
            "frequency": 1,
            "top_k": 5,
            "batch_size": 32,
            "frame": "val",
            "sample_first_crops": true
        }
    },
    "profile": {
      "use_pretrained_input_size": 224,
      "feature_layer": "avg_pool",
      "checkpoint": "efficientnetb0_notop.h5",
      "batch_size": 8
    }
}

-------------
Matplotlib created a temporary config/cache directory at /var/lib/condor/execute/slot1/dir_20093/matplotlib-wl_vuq_r because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
2021-11-02 22:05:47.901642: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 22:05:49,000 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Reading metadata form /local_group_storage/broad_data/michael/training/inputs/metadata/sc_1017.csv
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 75024 entries, 0 to 75023
Data columns (total 21 columns):
 #   Column                     Non-Null Count  Dtype
---  ------                     --------------  -----
 0   Metadata_Plate             75024 non-null  object
 1   Metadata_Well              75024 non-null  object
 2   Metadata_Site              75024 non-null  int64
 3   Metadata_broad_sample      75024 non-null  object
 4   Metadata_moa               75024 non-null  object
 5   Metadata_mmoles_per_liter  75024 non-null  float64
 6   Metadata_dose_recode       75024 non-null  int64
 7   RNA                        75024 non-null  object
 8   ER                         75024 non-null  object
 9   AGP                        75024 non-null  object
 10  Mito                       75024 non-null  object
 11  DNA                        75024 non-null  object
 12  Concentration              75024 non-null  object
 13  Treatment_ID               75024 non-null  int64
 14  Compound                   75024 non-null  object
 15  pert_iname                 75024 non-null  object
 16  Treatment_Replicate        75024 non-null  int64
 17  Treatment                  75024 non-null  object
 18  Plate_Map_Name             75024 non-null  object
 19  Split                      75024 non-null  object
 20  Metadata_Batch_Number      75024 non-null  int64
dtypes: float64(1), int64(5), object(15)
memory usage: 12.0+ MB
None
{'BRD-A02006392-001-10-7': 0, 'BRD-A02710418-003-11-8': 1, 'BRD-A03506276-001-01-5': 2, 'BRD-A03623303-045-09-5': 3, 'BRD-A04352665-001-05-3': 4, 'BRD-A04553218-050-16-2': 5, 'BRD-A05186015-003-19-8': 6, 'BRD-A05457250-001-05-0': 7, 'BRD-A05523972-001-01-5': 8, 'BRD-A05821830-341-01-5': 9, 'BRD-A06935312-001-04-3': 10, 'BRD-A07395371-003-10-0': 11, 'BRD-A07440155-003-25-4': 12, 'BRD-A07563059-035-01-3': 13, 'BRD-A07704283-001-01-3': 14, 'BRD-A07986123-001-02-8': 15, 'BRD-A09349126-001-10-7': 16, 'BRD-A09472452-015-23-4': 17, 'BRD-A09533288-003-31-2': 18, 'BRD-A10012892-001-01-9': 19, 'BRD-A10039652-001-01-2': 20, 'BRD-A10070317-003-28-3': 21, 'BRD-A10903566-003-07-7': 22, 'BRD-A10967948-003-06-3': 23, 'BRD-A10977446-001-12-1': 24, 'BRD-A11319535-001-03-6': 25, 'BRD-A12077521-003-01-5': 26, 'BRD-A12230535-001-06-7': 27, 'BRD-A12237696-001-04-2': 28, 'BRD-A12896037-001-04-3': 29, 'BRD-A12994259-001-02-1': 30, 'BRD-A13084692-001-17-3': 31, 'BRD-A13133631-001-04-0': 32, 'BRD-A13188892-066-21-5': 33, 'BRD-A14262390-065-01-8': 34, 'BRD-A14798026-001-02-6': 35, 'BRD-A14886633-001-01-6': 36, 'BRD-A14966924-003-07-7': 37, 'BRD-A15202882-003-02-7': 38, 'BRD-A15297126-001-04-3': 39, 'BRD-A15435692-003-02-3': 40, 'BRD-A15909516-001-06-6': 41, 'BRD-A16665823-001-02-0': 42, 'BRD-A16997652-001-02-3': 43, 'BRD-A17411484-001-11-9': 44, 'BRD-A17462676-003-11-6': 45, 'BRD-A17655518-001-24-4': 46, 'BRD-A18611368-001-01-5': 47, 'BRD-A18620900-001-05-2': 48, 'BRD-A18917088-001-04-9': 49, 'BRD-A19195498-050-14-1': 50, 'BRD-A19633847-050-32-1': 51, 'BRD-A19661776-003-27-6': 52, 'BRD-A19736161-001-06-7': 53, 'BRD-A20119038-003-07-8': 54, 'BRD-A20126139-001-04-2': 55, 'BRD-A20239487-001-24-9': 56, 'BRD-A20348246-001-15-8': 57, 'BRD-A21607826-003-05-1': 58, 'BRD-A21858158-001-23-5': 59, 'BRD-A22032524-074-06-5': 60, 'BRD-A22081593-001-11-1': 61, 'BRD-A22380646-236-05-8': 62, 'BRD-A22642447-001-01-9': 63, 'BRD-A23067620-300-01-3': 64, 'BRD-A24228527-213-01-9': 65, 'BRD-A24514565-001-09-7': 66, 'BRD-A24560335-300-01-2': 67, 'BRD-A25619068-003-03-4': 68, 'BRD-A26032986-050-02-1': 69, 'BRD-A26095496-001-04-0': 70, 'BRD-A26384407-001-25-1': 71, 'BRD-A26423207-001-01-0': 72, 'BRD-A26503646-001-16-6': 73, 'BRD-A26690767-066-01-9': 74, 'BRD-A26711594-003-10-6': 75, 'BRD-A27732521-003-08-3': 76, 'BRD-A28467416-002-01-0': 77, 'BRD-A28545468-003-16-6': 78, 'BRD-A28746609-001-11-5': 79, 'BRD-A28787076-001-04-8': 80, 'BRD-A29260609-003-26-0': 81, 'BRD-A29289453-001-04-7': 82, 'BRD-A29322418-237-04-0': 83, 'BRD-A29485665-001-12-8': 84, 'BRD-A29520968-001-02-7': 85, 'BRD-A29623586-001-01-3': 86, 'BRD-A29731977-001-04-5': 87, 'BRD-A29734509-011-13-6': 88, 'BRD-A29844814-300-01-5': 89, 'BRD-A29854054-236-12-6': 90, 'BRD-A30051119-002-01-8': 91, 'BRD-A30815329-001-10-5': 92, 'BRD-A30984645-001-01-5': 93, 'BRD-A31095847-001-02-3': 94, 'BRD-A31159102-003-30-4': 95, 'BRD-A31811760-001-06-7': 96, 'BRD-A32172948-001-07-6': 97, 'BRD-A33084557-001-06-6': 98, 'BRD-A33168282-003-18-0': 99, 'BRD-A33280134-001-04-7': 100, 'BRD-A33447119-001-10-8': 101, 'BRD-A33692381-001-01-9': 102, 'BRD-A33697453-008-02-4': 103, 'BRD-A33711280-003-03-1': 104, 'BRD-A34006693-001-15-4': 105, 'BRD-A34255068-001-34-5': 106, 'BRD-A36010170-001-04-0': 107, 'BRD-A36331462-001-02-1': 108, 'BRD-A38218502-001-01-2': 109, 'BRD-A38350138-001-04-9': 110, 'BRD-A38592941-001-02-7': 111, 'BRD-A39415247-001-10-4': 112, 'BRD-A39935389-001-05-9': 113, 'BRD-A42699921-001-02-8': 114, 'BRD-A44863528-001-13-2': 115, 'BRD-A45153512-001-01-0': 116, 'BRD-A46179541-311-02-0': 117, 'BRD-A47364545-003-02-6': 118, 'BRD-A47598013-004-16-0': 119, 'BRD-A48430263-003-17-2': 120, 'BRD-A48570745-001-02-9': 121, 'BRD-A49160188-003-12-7': 122, 'BRD-A49765801-001-04-1': 123, 'BRD-A49838158-001-01-1': 124, 'BRD-A50033377-001-02-8': 125, 'BRD-A50684349-003-02-9': 126, 'BRD-A50764878-003-02-8': 127, 'BRD-A51078674-003-01-0': 128, 'BRD-A51382177-236-03-0': 129, 'BRD-A51964809-003-12-6': 130, 'BRD-A52252998-001-01-3': 131, 'BRD-A52660433-066-02-1': 132, 'BRD-A52922642-001-03-7': 133, 'BRD-A53176877-001-04-3': 134, 'BRD-A53566267-001-01-9': 135, 'BRD-A53576514-048-14-3': 136, 'BRD-A54880345-001-20-9': 137, 'BRD-A55272860-001-15-3': 138, 'BRD-A55579717-001-04-0': 139, 'BRD-A55962179-001-22-1': 140, 'BRD-A56085258-001-01-8': 141, 'BRD-A56371469-001-03-3': 142, 'BRD-A58048407-001-18-8': 143, 'BRD-A59174698-003-18-5': 144, 'BRD-A61221616-001-04-3': 145, 'BRD-A61793559-001-15-6': 146, 'BRD-A62035778-004-03-6': 147, 'BRD-A62071884-001-04-6': 148, 'BRD-A62879835-001-04-2': 149, 'BRD-A63236097-001-01-3': 150, 'BRD-A63675168-001-01-6': 151, 'BRD-A65013509-003-24-4': 152, 'BRD-A65051990-001-12-9': 153, 'BRD-A65280694-003-13-7': 154, 'BRD-A67616246-001-07-9': 155, 'BRD-A67862938-034-14-9': 156, 'BRD-A68304895-003-02-2': 157, 'BRD-A68493689-001-01-9': 158, 'BRD-A68888262-003-15-1': 159, 'BRD-A68942014-003-01-7': 160, 'BRD-A69275535-001-01-5': 161, 'BRD-A69636825-003-04-7': 162, 'BRD-A69815203-001-07-6': 163, 'BRD-A70858459-001-01-7': 164, 'BRD-A70998768-004-01-1': 165, 'BRD-A73368467-003-17-6': 166, 'BRD-A73741725-001-02-8': 167, 'BRD-A74391928-051-01-3': 168, 'BRD-A74667430-001-23-6': 169, 'BRD-A74914197-001-02-9': 170, 'BRD-A74980173-001-11-9': 171, 'BRD-A75172220-001-04-0': 172, 'BRD-A75726477-003-21-3': 173, 'BRD-A78341343-001-01-6': 174, 'BRD-A78723049-001-01-2': 175, 'BRD-A78877355-001-03-0': 176, 'BRD-A79768653-001-12-0': 177, 'BRD-A79981887-003-16-4': 178, 'BRD-A80017228-001-25-7': 179, 'BRD-A80151636-066-04-8': 180, 'BRD-A81233518-004-16-1': 181, 'BRD-A82035391-001-02-7': 182, 'BRD-A82156122-001-01-9': 183, 'BRD-A82395837-001-01-9': 184, 'BRD-A82396632-008-29-0': 185, 'BRD-A83081521-001-02-3': 186, 'BRD-A84481105-003-20-6': 187, 'BRD-A85548292-001-01-8': 188, 'BRD-A86216746-046-02-6': 189, 'BRD-A86871940-001-01-9': 190, 'BRD-A87130939-001-07-9': 191, 'BRD-A87479750-001-02-7': 192, 'BRD-A87983072-001-01-1': 193, 'BRD-A88138582-001-04-8': 194, 'BRD-A89164055-001-03-3': 195, 'BRD-A89175223-051-14-8': 196, 'BRD-A90547603-001-02-5': 197, 'BRD-A90799790-001-19-9': 198, 'BRD-A91699651-316-10-9': 199, 'BRD-A92630576-050-24-1': 200, 'BRD-A92826379-001-01-5': 201, 'BRD-A93000692-001-08-1': 202, 'BRD-A93255169-001-28-3': 203, 'BRD-A93424738-001-04-8': 204, 'BRD-A93964801-003-03-3': 205, 'BRD-A94276798-001-01-4': 206, 'BRD-A94543220-001-24-7': 207, 'BRD-A94756469-001-04-7': 208, 'BRD-A95032015-065-01-2': 209, 'BRD-A95939040-001-01-2': 210, 'BRD-A96060515-004-01-6': 211, 'BRD-A96456596-001-02-2': 212, 'BRD-A96754982-001-01-4': 213, 'BRD-A97104540-004-15-0': 214, 'BRD-A97437073-050-14-5': 215, 'BRD-A97479839-003-13-3': 216, 'BRD-A97674275-001-11-8': 217, 'BRD-A97701745-001-16-0': 218, 'BRD-A97739905-001-26-5': 219, 'BRD-A97808748-001-03-8': 220, 'BRD-A98845662-036-03-7': 221, 'BRD-A98990573-003-01-3': 222, 'BRD-K04111260-001-10-0': 223, 'BRD-K04112579-001-07-0': 224, 'BRD-K04264130-001-01-4': 225, 'BRD-K04691817-001-01-8': 226, 'BRD-K04704168-003-14-3': 227, 'BRD-K04804440-001-09-5': 228, 'BRD-K04956647-003-02-5': 229, 'BRD-K05104363-001-10-0': 230, 'BRD-K05236810-001-19-0': 231, 'BRD-K05395900-322-05-4': 232, 'BRD-K05446112-001-01-8': 233, 'BRD-K05524748-003-04-4': 234, 'BRD-K05673000-236-12-1': 235, 'BRD-K05674516-001-02-5': 236, 'BRD-K05804044-001-06-0': 237, 'BRD-K05977355-001-19-0': 238, 'BRD-K06240250-001-01-6': 239, 'BRD-K06335600-003-20-7': 240, 'BRD-K06388322-312-02-6': 241, 'BRD-K06557128-001-07-0': 242, 'BRD-K06762493-001-08-1': 243, 'BRD-K06858286-001-01-3': 244, 'BRD-K06878038-001-18-6': 245, 'BRD-K06900071-001-01-2': 246, 'BRD-K07106112-003-03-8': 247, 'BRD-K07160047-001-01-3': 248, 'BRD-K07208025-001-29-7': 249, 'BRD-K07220430-001-18-4': 250, 'BRD-K07237224-001-19-6': 251, 'BRD-K07310275-001-02-5': 252, 'BRD-K07609981-001-01-7': 253, 'BRD-K07691486-001-15-5': 254, 'BRD-K07798980-001-01-9': 255, 'BRD-K07857022-002-01-1': 256, 'BRD-K07954936-001-01-3': 257, 'BRD-K08248804-001-01-8': 258, 'BRD-K08252256-236-33-8': 259, 'BRD-K08547377-394-03-5': 260, 'BRD-K08586861-001-01-1': 261, 'BRD-K08703257-001-12-1': 262, 'BRD-K08799216-001-05-3': 263, 'BRD-K08924299-003-06-1': 264, 'BRD-K08976401-001-18-5': 265, 'BRD-K09078998-001-01-4': 266, 'BRD-K09090949-001-01-9': 267, 'BRD-K09132007-001-07-5': 268, 'BRD-K09255212-001-16-6': 269, 'BRD-K09372874-001-01-0': 270, 'BRD-K09397065-003-06-1': 271, 'BRD-K09426783-300-01-0': 272, 'BRD-K09471561-001-18-2': 273, 'BRD-K09549677-300-03-4': 274, 'BRD-K09602097-001-13-6': 275, 'BRD-K09951645-001-06-8': 276, 'BRD-K10670311-001-15-5': 277, 'BRD-K10843433-001-22-7': 278, 'BRD-K10859802-001-01-0': 279, 'BRD-K10961822-001-05-1': 280, 'BRD-K11071038-001-01-7': 281, 'BRD-K11073688-001-01-6': 282, 'BRD-K11153516-001-05-5': 283, 'BRD-K11196887-001-21-2': 284, 'BRD-K11267252-001-04-4': 285, 'BRD-K11433652-001-17-0': 286, 'BRD-K12184916-001-15-4': 287, 'BRD-K12219985-001-26-1': 288, 'BRD-K12423485-001-01-7': 289, 'BRD-K12539416-001-01-4': 290, 'BRD-K12609457-001-03-1': 291, 'BRD-K12737986-001-01-4': 292, 'BRD-K12787259-001-04-3': 293, 'BRD-K12867552-001-04-7': 294, 'BRD-K12885236-001-02-7': 295, 'BRD-K12932420-001-02-3': 296, 'BRD-K12994359-001-18-4': 297, 'BRD-K13154216-001-01-3': 298, 'BRD-K13296708-001-05-8': 299, 'BRD-K13356952-001-25-1': 300, 'BRD-K13390322-001-06-3': 301, 'BRD-K13662825-001-07-5': 302, 'BRD-K13756951-001-01-4': 303, 'BRD-K13926615-003-03-3': 304, 'BRD-K14175878-001-01-6': 305, 'BRD-K14704277-001-22-6': 306, 'BRD-K15010214-364-02-7': 307, 'BRD-K15108141-001-06-6': 308, 'BRD-K15179879-001-03-2': 309, 'BRD-K15318383-201-01-5': 310, 'BRD-K15409150-001-05-8': 311, 'BRD-K15502390-001-20-9': 312, 'BRD-K15507868-001-03-7': 313, 'BRD-K15567136-003-27-2': 314, 'BRD-K15766189-001-09-8': 315, 'BRD-K15933101-003-06-1': 316, 'BRD-K15976406-001-03-3': 317, 'BRD-K16077845-001-06-1': 318, 'BRD-K16195444-003-26-0': 319, 'BRD-K16295392-003-01-3': 320, 'BRD-K16542329-001-13-5': 321, 'BRD-K16757695-050-02-5': 322, 'BRD-K16761703-001-03-8': 323, 'BRD-K16762525-001-01-6': 324, 'BRD-K16803204-001-01-6': 325, 'BRD-K17026858-001-01-2': 326, 'BRD-K17068645-003-04-2': 327, 'BRD-K17075857-001-17-6': 328, 'BRD-K17498618-344-02-6': 329, 'BRD-K17513304-001-01-9': 330, 'BRD-K17555800-003-01-5': 331, 'BRD-K17561142-003-32-5': 332, 'BRD-K17705806-003-04-4': 333, 'BRD-K17743125-001-08-4': 334, 'BRD-K17849083-001-31-1': 335, 'BRD-K17930269-001-01-8': 336, 'BRD-K17944737-001-02-1': 337, 'BRD-K17953908-001-01-7': 338, 'BRD-K18157228-001-01-7': 339, 'BRD-K18194590-065-08-0': 340, 'BRD-K18324993-001-01-6': 341, 'BRD-K18779551-003-07-8': 342, 'BRD-K18850819-001-04-6': 343, 'BRD-K18895904-001-16-1': 344, 'BRD-K18922609-004-23-1': 345, 'BRD-K19061412-001-02-4': 346, 'BRD-K19111024-001-20-9': 347, 'BRD-K19284129-001-02-6': 348, 'BRD-K19352500-070-12-4': 349, 'BRD-K19388745-003-01-7': 350, 'BRD-K19412355-001-01-0': 351, 'BRD-K19416115-001-05-3': 352, 'BRD-K19438463-001-05-5': 353, 'BRD-K19456237-001-27-6': 354, 'BRD-K19477839-001-07-6': 355, 'BRD-K19687926-379-07-4': 356, 'BRD-K19741547-003-01-7': 357, 'BRD-K19761926-001-02-8': 358, 'BRD-K20008181-001-01-3': 359, 'BRD-K20079257-001-09-6': 360, 'BRD-K20722021-001-02-1': 361, 'BRD-K20738689-001-01-2': 362, 'BRD-K20745393-003-01-0': 363, 'BRD-K20897876-001-10-0': 364, 'BRD-K20920669-304-09-1': 365, 'BRD-K20958582-001-01-4': 366, 'BRD-K21396683-001-04-8': 367, 'BRD-K21450440-001-14-6': 368, 'BRD-K21548250-003-19-1': 369, 'BRD-K21680192-300-14-4': 370, 'BRD-K21884483-001-03-7': 371, 'BRD-K21908111-001-01-8': 372, 'BRD-K22024824-001-03-7': 373, 'BRD-K22031190-001-23-6': 374, 'BRD-K22097830-001-01-9': 375, 'BRD-K22134346-001-22-3': 376, 'BRD-K22482860-001-21-4': 377, 'BRD-K22662435-001-18-3': 378, 'BRD-K22749967-046-02-3': 379, 'BRD-K22822991-001-02-3': 380, 'BRD-K22848513-001-01-9': 381, 'BRD-K22936972-003-23-6': 382, 'BRD-K22969690-001-04-2': 383, 'BRD-K23082237-003-01-5': 384, 'BRD-K23190681-001-01-1': 385, 'BRD-K23204545-001-16-4': 386, 'BRD-K23228615-001-02-8': 387, 'BRD-K23363278-001-02-1': 388, 'BRD-K23499943-003-01-6': 389, 'BRD-K23672206-001-01-4': 390, 'BRD-K23677682-003-01-2': 391, 'BRD-K23976833-001-01-0': 392, 'BRD-K24219278-001-01-6': 393, 'BRD-K24616672-003-20-1': 394, 'BRD-K24723746-036-02-5': 395, 'BRD-K24771047-001-01-6': 396, 'BRD-K24844714-001-24-5': 397, 'BRD-K24943235-001-01-3': 398, 'BRD-K24968862-001-01-0': 399, 'BRD-K25114078-003-08-1': 400, 'BRD-K25140590-001-03-0': 401, 'BRD-K25361343-001-01-6': 402, 'BRD-K25394294-001-14-9': 403, 'BRD-K25412176-001-01-9': 404, 'BRD-K25433859-003-25-4': 405, 'BRD-K25630527-001-03-8': 406, 'BRD-K25943794-001-02-3': 407, 'BRD-K26011976-001-01-0': 408, 'BRD-K26325692-003-01-3': 409, 'BRD-K26341917-001-01-3': 410, 'BRD-K26603252-003-04-9': 411, 'BRD-K26619122-001-02-1': 412, 'BRD-K26667523-001-02-5': 413, 'BRD-K26823213-001-02-9': 414, 'BRD-K27182532-001-02-3': 415, 'BRD-K27184429-300-01-3': 416, 'BRD-K27204852-001-01-9': 417, 'BRD-K27938825-001-02-4': 418, 'BRD-K27955832-001-02-9': 419, 'BRD-K28115081-001-02-7': 420, 'BRD-K28143534-003-25-9': 421, 'BRD-K28183345-003-11-4': 422, 'BRD-K28217197-001-01-4': 423, 'BRD-K28307902-001-21-7': 424, 'BRD-K28428262-001-04-1': 425, 'BRD-K28456624-001-01-1': 426, 'BRD-K28542495-003-13-5': 427, 'BRD-K28667793-001-28-1': 428, 'BRD-K28731095-001-01-7': 429, 'BRD-K28822270-001-01-1': 430, 'BRD-K28912512-001-23-2': 431, 'BRD-K28971625-003-01-4': 432, 'BRD-K28984613-001-01-5': 433, 'BRD-K29133151-001-03-2': 434, 'BRD-K29322660-001-01-9': 435, 'BRD-K29458283-001-29-9': 436, 'BRD-K29530284-001-06-2': 437, 'BRD-K29582115-066-01-2': 438, 'BRD-K29673530-001-05-4': 439, 'BRD-K29735307-001-02-9': 440, 'BRD-K29950728-048-17-4': 441, 'BRD-K30020243-051-02-5': 442, 'BRD-K30126819-304-02-7': 443, 'BRD-K30421593-050-04-9': 444, 'BRD-K30550578-001-01-3': 445, 'BRD-K31092604-003-03-5': 446, 'BRD-K31111078-001-04-2': 447, 'BRD-K31135544-001-07-0': 448, 'BRD-K31309378-001-01-5': 449, 'BRD-K31339321-001-03-6': 450, 'BRD-K31342827-001-08-8': 451, 'BRD-K31447894-236-01-0': 452, 'BRD-K31476763-001-01-5': 453, 'BRD-K31495718-001-01-1': 454, 'BRD-K31519811-001-02-2': 455, 'BRD-K31627533-001-09-5': 456, 'BRD-K31812033-003-11-0': 457, 'BRD-K31841515-001-07-8': 458, 'BRD-K31928526-001-02-1': 459, 'BRD-K32101625-001-01-6': 460, 'BRD-K32107296-001-16-9': 461, 'BRD-K32164935-001-30-8': 462, 'BRD-K32218650-001-01-6': 463, 'BRD-K32247306-001-29-4': 464, 'BRD-K32285926-001-02-1': 465, 'BRD-K32318651-001-23-7': 466, 'BRD-K32405725-001-02-8': 467, 'BRD-K32501161-300-06-2': 468, 'BRD-K32977963-001-05-0': 469, 'BRD-K33106058-001-16-8': 470, 'BRD-K33127281-001-05-6': 471, 'BRD-K33141550-003-05-7': 472, 'BRD-K33226500-001-01-0': 473, 'BRD-K33379087-001-07-5': 474, 'BRD-K33453211-003-11-5': 475, 'BRD-K33610132-001-02-9': 476, 'BRD-K33732501-004-01-0': 477, 'BRD-K33852358-001-09-9': 478, 'BRD-K33882852-003-02-8': 479, 'BRD-K34008116-001-01-7': 480, 'BRD-K34022604-001-06-6': 481, 'BRD-K34154330-003-06-4': 482, 'BRD-K34157611-001-16-0': 483, 'BRD-K34185671-001-02-8': 484, 'BRD-K34313798-001-01-6': 485, 'BRD-K34415467-003-13-0': 486, 'BRD-K34469523-003-03-0': 487, 'BRD-K34776109-001-16-6': 488, 'BRD-K34888156-213-01-4': 489, 'BRD-K35007173-001-07-5': 490, 'BRD-K35169477-001-01-9': 491, 'BRD-K35189033-001-26-1': 492, 'BRD-K35245662-001-01-2': 493, 'BRD-K35520305-001-17-7': 494, 'BRD-K35586044-003-15-4': 495, 'BRD-K35589454-003-01-1': 496, 'BRD-K35629949-001-02-0': 497, 'BRD-K35719256-001-02-6': 498, 'BRD-K35775715-001-03-1': 499, 'BRD-K36269323-300-02-6': 500, 'BRD-K36270037-001-01-7': 501, 'BRD-K36280065-048-01-2': 502, 'BRD-K36386086-001-01-1': 503, 'BRD-K36467523-001-02-8': 504, 'BRD-K36627727-001-05-4': 505, 'BRD-K36732695-001-01-9': 506, 'BRD-K36740062-001-06-6': 507, 'BRD-K36862742-001-25-6': 508, 'BRD-K37111771-300-02-6': 509, 'BRD-K37687095-001-06-9': 510, 'BRD-K37694030-003-12-7': 511, 'BRD-K37714784-305-02-1': 512, 'BRD-K38287497-001-01-2': 513, 'BRD-K38852836-001-02-1': 514, 'BRD-K39503511-001-03-9': 515, 'BRD-K40175214-001-11-6': 516, 'BRD-K40797222-001-01-8': 517, 'BRD-K40870905-001-01-7': 518, 'BRD-K41160163-001-06-8': 519, 'BRD-K41599323-001-02-3': 520, 'BRD-K42191735-001-05-3': 521, 'BRD-K42805893-001-04-9': 522, 'BRD-K42898655-001-01-8': 523, 'BRD-K43586850-001-02-9': 524, 'BRD-K43723251-001-01-5': 525, 'BRD-K43797669-001-30-4': 526, 'BRD-K44366189-001-01-9': 527, 'BRD-K44408410-001-17-6': 528, 'BRD-K44771174-066-01-0': 529, 'BRD-K44844162-001-01-6': 530, 'BRD-K44974079-001-01-3': 531, 'BRD-K45033733-001-12-2': 532, 'BRD-K45071273-003-25-6': 533, 'BRD-K45117373-001-02-9': 534, 'BRD-K45152786-001-08-4': 535, 'BRD-K45158365-001-11-4': 536, 'BRD-K45245728-335-01-4': 537, 'BRD-K45252063-001-13-6': 538, 'BRD-K45275534-001-01-3': 539, 'BRD-K45330754-001-21-7': 540, 'BRD-K45542189-048-22-1': 541, 'BRD-K45746021-003-01-9': 542, 'BRD-K45924332-001-16-8': 543, 'BRD-K46018455-001-27-6': 544, 'BRD-K46133855-304-03-8': 545, 'BRD-K46290096-001-01-1': 546, 'BRD-K46386702-001-02-1': 547, 'BRD-K46424862-001-14-1': 548, 'BRD-K46604138-001-01-3': 549, 'BRD-K46654563-238-01-0': 550, 'BRD-K46692793-004-01-8': 551, 'BRD-K46937689-001-15-0': 552, 'BRD-K46970505-003-01-9': 553, 'BRD-K47095176-001-01-6': 554, 'BRD-K47539947-001-03-7': 555, 'BRD-K47554101-001-01-2': 556, 'BRD-K47639036-003-06-6': 557, 'BRD-K47642186-001-01-3': 558, 'BRD-K47780086-001-07-9': 559, 'BRD-K47936004-003-11-4': 560, 'BRD-K47976015-001-01-2': 561, 'BRD-K48068743-001-01-6': 562, 'BRD-K48195801-001-01-6': 563, 'BRD-K48213016-001-01-8': 564, 'BRD-K48367671-001-05-9': 565, 'BRD-K48461310-234-01-3': 566, 'BRD-K48578705-001-16-8': 567, 'BRD-K48812570-001-02-3': 568, 'BRD-K48892307-001-04-1': 569, 'BRD-K48894757-001-01-8': 570, 'BRD-K49075727-001-08-5': 571, 'BRD-K49111258-003-29-7': 572, 'BRD-K49215523-001-04-2': 573, 'BRD-K49350383-001-13-7': 574, 'BRD-K49404994-001-10-9': 575, 'BRD-K49456274-001-01-9': 576, 'BRD-K49555808-001-03-9': 577, 'BRD-K49671696-045-08-5': 578, 'BRD-K49685476-001-15-9': 579, 'BRD-K49807096-003-15-5': 580, 'BRD-K49840922-001-05-1': 581, 'BRD-K49865102-001-08-4': 582, 'BRD-K50031829-001-01-6': 583, 'BRD-K50133271-001-18-7': 584, 'BRD-K50163129-001-01-4': 585, 'BRD-K50168500-001-07-9': 586, 'BRD-K50398167-236-22-7': 587, 'BRD-K50859149-001-19-5': 588, 'BRD-K50938287-036-13-8': 589, 'BRD-K51040301-001-02-1': 590, 'BRD-K51143828-003-03-1': 591, 'BRD-K51263939-001-08-6': 592, 'BRD-K51313569-003-03-3': 593, 'BRD-K51324732-001-01-0': 594, 'BRD-K51333959-003-01-3': 595, 'BRD-K51350053-048-16-5': 596, 'BRD-K51485625-001-08-4': 597, 'BRD-K51662849-001-05-4': 598, 'BRD-K51747290-001-13-1': 599, 'BRD-K51967704-001-03-6': 600, 'BRD-K52020312-001-26-8': 601, 'BRD-K52172416-001-11-4': 602, 'BRD-K52183142-001-01-3': 603, 'BRD-K52233191-001-02-4': 604, 'BRD-K52313696-001-12-3': 605, 'BRD-K52618540-001-09-9': 606, 'BRD-K52662033-003-21-2': 607, 'BRD-K52751261-001-06-1': 608, 'BRD-K52911425-001-09-8': 609, 'BRD-K52959329-238-01-9': 610, 'BRD-K52989797-003-26-4': 611, 'BRD-K53061490-003-13-9': 612, 'BRD-K53414658-001-08-2': 613, 'BRD-K53517854-051-01-4': 614, 'BRD-K53581288-001-02-9': 615, 'BRD-K53665955-001-03-0': 616, 'BRD-K53765467-001-02-1': 617, 'BRD-K53814070-310-01-3': 618, 'BRD-K53857191-001-22-7': 619, 'BRD-K53963539-004-02-0': 620, 'BRD-K53972329-001-07-0': 621, 'BRD-K53979406-003-02-8': 622, 'BRD-K54006094-051-01-7': 623, 'BRD-K54416256-001-19-9': 624, 'BRD-K54472332-001-03-4': 625, 'BRD-K54770957-001-04-3': 626, 'BRD-K54847683-001-03-2': 627, 'BRD-K54936858-001-01-6': 628, 'BRD-K55026842-001-01-4': 629, 'BRD-K55127134-300-11-2': 630, 'BRD-K55512740-001-01-6': 631, 'BRD-K55748775-001-02-2': 632, 'BRD-K55781385-001-01-7': 633, 'BRD-K55847762-304-01-7': 634, 'BRD-K55966568-001-05-4': 635, 'BRD-K56032964-001-02-1': 636, 'BRD-K56104152-008-04-1': 637, 'BRD-K56195681-001-01-0': 638, 'BRD-K56291712-001-01-0': 639, 'BRD-K56301217-001-07-4': 640, 'BRD-K56334280-001-05-1': 641, 'BRD-K56343971-001-10-6': 642, 'BRD-K56405753-001-02-4': 643, 'BRD-K56558538-003-11-9': 644, 'BRD-K56751279-300-01-4': 645, 'BRD-K56800335-015-04-9': 646, 'BRD-K56810756-001-03-0': 647, 'BRD-K56844688-003-01-2': 648, 'BRD-K56851771-001-06-8': 649, 'BRD-K56957086-001-06-3': 650, 'BRD-K57041787-001-02-6': 651, 'BRD-K57080016-001-15-9': 652, 'BRD-K57169635-001-04-5': 653, 'BRD-K57222227-001-30-1': 654, 'BRD-K57252450-001-02-5': 655, 'BRD-K57371763-001-01-7': 656, 'BRD-K57432881-003-21-8': 657, 'BRD-K57545991-050-23-1': 658, 'BRD-K57569181-001-27-5': 659, 'BRD-K57764956-001-02-8': 660, 'BRD-K58010567-003-02-2': 661, 'BRD-K58114536-001-01-6': 662, 'BRD-K58211978-001-01-5': 663, 'BRD-K58435339-001-03-0': 664, 'BRD-K58486055-001-02-7': 665, 'BRD-K58501140-002-01-0': 666, 'BRD-K58736316-001-09-5': 667, 'BRD-K58951486-004-01-5': 668, 'BRD-K59013864-001-01-1': 669, 'BRD-K59037100-001-14-7': 670, 'BRD-K59058766-003-21-9': 671, 'BRD-K59197931-001-04-5': 672, 'BRD-K59227464-334-02-4': 673, 'BRD-K59317601-001-05-5': 674, 'BRD-K59325863-001-02-8': 675, 'BRD-K59331299-001-01-2': 676, 'BRD-K59332007-300-02-7': 677, 'BRD-K59433843-001-01-7': 678, 'BRD-K59436580-001-01-7': 679, 'BRD-K59506194-015-04-9': 680, 'BRD-K59573506-001-01-8': 681, 'BRD-K59574735-001-11-8': 682, 'BRD-K59632282-052-03-1': 683, 'BRD-K59929863-001-01-9': 684, 'BRD-K60038276-001-09-0': 685, 'BRD-K60341624-001-02-2': 686, 'BRD-K60585088-001-01-5': 687, 'BRD-K60866521-001-07-1': 688, 'BRD-K61036791-001-01-6': 689, 'BRD-K61195623-001-01-4': 690, 'BRD-K61250553-003-32-2': 691, 'BRD-K61397605-001-03-4': 692, 'BRD-K61452026-001-04-6': 693, 'BRD-K61691541-001-01-1': 694, 'BRD-K61693562-300-01-7': 695, 'BRD-K62196610-001-01-6': 696, 'BRD-K62200014-003-10-5': 697, 'BRD-K62310379-001-10-5': 698, 'BRD-K62363391-001-24-9': 699, 'BRD-K62387885-001-01-9': 700, 'BRD-K62391742-001-03-0': 701, 'BRD-K62398570-300-01-2': 702, 'BRD-K62737565-003-02-6': 703, 'BRD-K62858456-001-01-8': 704, 'BRD-K62965247-001-04-9': 705, 'BRD-K62996583-001-10-3': 706, 'BRD-K63550407-001-12-7': 707, 'BRD-K63630713-001-25-8': 708, 'BRD-K63675182-003-23-6': 709, 'BRD-K63750851-001-20-7': 710, 'BRD-K63861289-001-19-6': 711, 'BRD-K64504314-001-01-8': 712, 'BRD-K64538373-001-01-4': 713, 'BRD-K65991129-001-02-9': 714, 'BRD-K66035042-001-10-1': 715, 'BRD-K66937583-001-01-2': 716, 'BRD-K67017579-001-28-1': 717, 'BRD-K67043667-001-26-4': 718, 'BRD-K67068943-001-01-0': 719, 'BRD-K67080878-001-15-4': 720, 'BRD-K67102207-236-07-7': 721, 'BRD-K67783091-001-26-1': 722, 'BRD-K67789209-001-01-0': 723, 'BRD-K67868012-001-07-6': 724, 'BRD-K67901620-001-02-0': 725, 'BRD-K67966701-001-11-6': 726, 'BRD-K68065987-300-09-1': 727, 'BRD-K68095457-001-10-1': 728, 'BRD-K68132782-003-13-8': 729, 'BRD-K68232413-001-01-2': 730, 'BRD-K68346641-001-02-2': 731, 'BRD-K68392338-003-02-0': 732, 'BRD-K68552125-001-05-3': 733, 'BRD-K68693535-001-03-4': 734, 'BRD-K68747584-001-02-0': 735, 'BRD-K68867920-051-11-5': 736, 'BRD-K68870568-066-01-5': 737, 'BRD-K68938568-001-01-7': 738, 'BRD-K69001009-001-02-8': 739, 'BRD-K69116396-001-04-1': 740, 'BRD-K69236721-001-02-7': 741, 'BRD-K69247067-001-01-8': 742, 'BRD-K69726342-238-02-4': 743, 'BRD-K69726595-001-01-2': 744, 'BRD-K69776681-001-03-8': 745, 'BRD-K70301465-001-02-6': 746, 'BRD-K70301876-034-13-7': 747, 'BRD-K70330367-003-07-9': 748, 'BRD-K70358946-001-15-7': 749, 'BRD-K70401845-003-09-6': 750, 'BRD-K70463136-001-01-5': 751, 'BRD-K70464547-003-01-2': 752, 'BRD-K70490179-300-01-2': 753, 'BRD-K70507123-001-09-7': 754, 'BRD-K70511574-001-06-9': 755, 'BRD-K70557564-305-03-6': 756, 'BRD-K70610771-001-02-9': 757, 'BRD-K70792160-003-04-6': 758, 'BRD-K70912147-001-01-8': 759, 'BRD-K70914287-300-02-8': 760, 'BRD-K70924353-001-01-2': 761, 'BRD-K71058253-001-01-9': 762, 'BRD-K71075609-003-01-0': 763, 'BRD-K71106091-001-06-1': 764, 'BRD-K71164191-001-01-0': 765, 'BRD-K71221037-001-01-6': 766, 'BRD-K71281111-001-04-3': 767, 'BRD-K71289571-001-11-4': 768, 'BRD-K71480163-001-01-4': 769, 'BRD-K71603915-003-01-8': 770, 'BRD-K71822263-001-03-2': 771, 'BRD-K72005722-001-01-2': 772, 'BRD-K72093121-001-16-3': 773, 'BRD-K72166146-066-05-4': 774, 'BRD-K72215350-001-06-5': 775, 'BRD-K72222507-003-16-8': 776, 'BRD-K72414522-001-06-7': 777, 'BRD-K72827473-001-01-0': 778, 'BRD-K72922393-003-15-2': 779, 'BRD-K73088654-001-01-9': 780, 'BRD-K73107279-003-12-5': 781, 'BRD-K73109821-001-20-1': 782, 'BRD-K73196317-003-14-8': 783, 'BRD-K73237276-001-01-0': 784, 'BRD-K73319509-001-08-0': 785, 'BRD-K73381542-003-23-4': 786, 'BRD-K73541271-001-03-6': 787, 'BRD-K73691377-001-01-6': 788, 'BRD-K73794685-001-01-5': 789, 'BRD-K73999723-001-11-3': 790, 'BRD-K74057757-001-01-9': 791, 'BRD-K74065929-001-07-2': 792, 'BRD-K74141488-003-11-2': 793, 'BRD-K74190368-001-04-3': 794, 'BRD-K74195153-050-12-1': 795, 'BRD-K74339692-001-01-9': 796, 'BRD-K74363950-004-01-0': 797, 'BRD-K74371986-001-01-7': 798, 'BRD-K74514084-001-03-9': 799, 'BRD-K74717603-001-02-2': 800, 'BRD-K74763371-002-04-0': 801, 'BRD-K75089421-003-24-5': 802, 'BRD-K75295174-001-05-0': 803, 'BRD-K75641298-003-25-0': 804, 'BRD-K75649340-001-13-1': 805, 'BRD-K75699339-057-08-1': 806, 'BRD-K75844781-003-08-0': 807, 'BRD-K75911534-001-01-6': 808, 'BRD-K75958547-238-01-0': 809, 'BRD-K76022557-003-02-7': 810, 'BRD-K76197012-001-01-2': 811, 'BRD-K76205745-237-16-5': 812, 'BRD-K76617868-003-11-9': 813, 'BRD-K76674262-001-03-3': 814, 'BRD-K76775527-001-30-2': 815, 'BRD-K76810206-001-07-3': 816, 'BRD-K76841105-001-04-7': 817, 'BRD-K76908866-001-07-6': 818, 'BRD-K76953762-001-08-5': 819, 'BRD-K77396579-300-01-0': 820, 'BRD-K77561571-001-01-1': 821, 'BRD-K77641333-003-27-1': 822, 'BRD-K77685957-300-09-1': 823, 'BRD-K77695569-001-30-0': 824, 'BRD-K77908580-001-09-6': 825, 'BRD-K77947974-001-16-3': 826, 'BRD-K77987382-001-13-2': 827, 'BRD-K78010432-001-21-5': 828, 'BRD-K78096648-001-05-7': 829, 'BRD-K78113049-001-16-2': 830, 'BRD-K78118466-001-03-3': 831, 'BRD-K78303961-001-02-3': 832, 'BRD-K78431006-001-10-2': 833, 'BRD-K78485176-001-07-8': 834, 'BRD-K78567475-001-01-4': 835, 'BRD-K78659596-001-03-9': 836, 'BRD-K79102359-003-01-6': 837, 'BRD-K79131256-001-17-9': 838, 'BRD-K79254416-001-22-6': 839, 'BRD-K79404599-001-09-3': 840, 'BRD-K79501723-001-04-6': 841, 'BRD-K79595931-312-01-3': 842, 'BRD-K79602928-003-19-9': 843, 'BRD-K79759585-048-04-8': 844, 'BRD-K79989959-001-01-4': 845, 'BRD-K80082640-001-01-0': 846, 'BRD-K80267133-001-17-7': 847, 'BRD-K80343549-001-02-6': 848, 'BRD-K80396088-001-12-0': 849, 'BRD-K80535353-001-01-4': 850, 'BRD-K80608265-001-01-6': 851, 'BRD-K80700417-001-04-2': 852, 'BRD-K81144366-003-19-7': 853, 'BRD-K81258678-001-01-0': 854, 'BRD-K81272440-236-13-5': 855, 'BRD-K81332461-001-01-4': 856, 'BRD-K81473089-003-26-1': 857, 'BRD-K81694556-003-01-9': 858, 'BRD-K81916719-001-13-9': 859, 'BRD-K81957469-001-01-0': 860, 'BRD-K82164249-001-03-5': 861, 'BRD-K82225283-001-03-1': 862, 'BRD-K82244583-001-01-3': 863, 'BRD-K82467063-001-02-7': 864, 'BRD-K82522873-001-01-1': 865, 'BRD-K82603084-408-01-1': 866, 'BRD-K82746043-001-15-1': 867, 'BRD-K82767007-001-01-1': 868, 'BRD-K82795137-001-26-2': 869, 'BRD-K82846253-001-15-4': 870, 'BRD-K82928847-001-04-7': 871, 'BRD-K82941592-238-04-5': 872, 'BRD-K82967685-300-01-2': 873, 'BRD-K83057217-001-01-2': 874, 'BRD-K83508485-001-02-7': 875, 'BRD-K83699324-001-01-1': 876, 'BRD-K83720053-001-03-8': 877, 'BRD-K83794243-001-01-8': 878, 'BRD-K83837640-001-04-8': 879, 'BRD-K83963101-001-06-9': 880, 'BRD-K84091759-001-07-1': 881, 'BRD-K84163249-001-01-9': 882, 'BRD-K84564571-001-02-4': 883, 'BRD-K84748119-050-01-1': 884, 'BRD-K84783599-001-01-0': 885, 'BRD-K84794093-001-07-5': 886, 'BRD-K84798689-236-02-9': 887, 'BRD-K84986517-001-01-8': 888, 'BRD-K84996356-001-01-1': 889, 'BRD-K85090592-008-22-7': 890, 'BRD-K85119730-001-28-9': 891, 'BRD-K85140930-001-12-7': 892, 'BRD-K85307935-236-09-5': 893, 'BRD-K85337334-004-02-6': 894, 'BRD-K85606544-001-09-1': 895, 'BRD-K85679373-001-01-1': 896, 'BRD-K85751432-001-03-3': 897, 'BRD-K85833139-001-01-9': 898, 'BRD-K85925969-001-17-4': 899, 'BRD-K86301799-001-34-8': 900, 'BRD-K86307448-001-17-5': 901, 'BRD-K86797399-001-04-4': 902, 'BRD-K86882815-001-03-2': 903, 'BRD-K86892782-001-17-0': 904, 'BRD-K87156652-001-12-7': 905, 'BRD-K87300616-001-01-9': 906, 'BRD-K87737963-001-06-0': 907, 'BRD-K87782578-001-01-4': 908, 'BRD-K87909389-003-03-4': 909, 'BRD-K87990216-001-10-2': 910, 'BRD-K88358234-003-04-8': 911, 'BRD-K88429204-001-35-1': 912, 'BRD-K88506063-001-01-8': 913, 'BRD-K88544581-001-06-1': 914, 'BRD-K88611939-001-22-4': 915, 'BRD-K88789588-001-14-9': 916, 'BRD-K88807631-001-01-3': 917, 'BRD-K89014967-001-04-3': 918, 'BRD-K89104321-003-14-8': 919, 'BRD-K89208535-051-01-5': 920, 'BRD-K89274813-001-02-3': 921, 'BRD-K89348303-001-14-7': 922, 'BRD-K89375097-300-08-8': 923, 'BRD-K89402695-001-02-3': 924, 'BRD-K89561498-001-01-7': 925, 'BRD-K89704198-001-12-3': 926, 'BRD-K89732114-300-08-9': 927, 'BRD-K89997465-003-43-0': 928, 'BRD-K90239174-001-01-8': 929, 'BRD-K90333595-003-21-4': 930, 'BRD-K90777969-300-01-2': 931, 'BRD-K90825648-001-02-0': 932, 'BRD-K90868879-001-03-8': 933, 'BRD-K90948141-001-01-4': 934, 'BRD-K91111634-001-01-2': 935, 'BRD-K91159026-001-01-7': 936, 'BRD-K91263825-003-21-4': 937, 'BRD-K91290917-300-01-8': 938, 'BRD-K91308639-001-02-7': 939, 'BRD-K91336023-003-01-0': 940, 'BRD-K91456750-238-01-7': 941, 'BRD-K91495480-001-02-2': 942, 'BRD-K91544578-001-03-8': 943, 'BRD-K91740057-001-19-8': 944, 'BRD-K91822704-003-07-2': 945, 'BRD-K91825936-001-01-2': 946, 'BRD-K92041145-001-09-5': 947, 'BRD-K92049597-001-20-8': 948, 'BRD-K92093830-003-30-8': 949, 'BRD-K92303087-001-01-6': 950, 'BRD-K92428153-001-04-4': 951, 'BRD-K92428232-001-10-6': 952, 'BRD-K92441787-001-04-1': 953, 'BRD-K92731339-227-04-9': 954, 'BRD-K92968657-001-01-6': 955, 'BRD-K92984783-003-05-7': 956, 'BRD-K93208532-001-02-5': 957, 'BRD-K93461745-003-25-0': 958, 'BRD-K93645900-001-11-3': 959, 'BRD-K93754473-048-20-2': 960, 'BRD-K93779381-001-01-9': 961, 'BRD-K93869735-001-01-1': 962, 'BRD-K94420399-001-01-9': 963, 'BRD-K94534639-001-02-5': 964, 'BRD-K95142244-001-01-5': 965, 'BRD-K95260951-050-03-1': 966, 'BRD-K95412502-003-01-5': 967, 'BRD-K95739795-001-03-7': 968, 'BRD-K95773607-004-03-8': 969, 'BRD-K95880107-001-02-4': 970, 'BRD-K95901403-001-04-5': 971, 'BRD-K95921201-001-14-6': 972, 'BRD-K96042922-001-09-8': 973, 'BRD-K96123349-236-02-8': 974, 'BRD-K96194081-001-10-2': 975, 'BRD-K96342952-001-01-2': 976, 'BRD-K96550715-001-02-6': 977, 'BRD-K96615647-001-01-2': 978, 'BRD-K96671969-001-03-1': 979, 'BRD-K96720755-001-02-6': 980, 'BRD-K96740444-001-02-1': 981, 'BRD-K96862998-001-15-5': 982, 'BRD-K97010173-001-04-1': 983, 'BRD-K97045029-001-02-7': 984, 'BRD-K97101532-001-02-8': 985, 'BRD-K97158071-001-18-1': 986, 'BRD-K97181089-003-24-7': 987, 'BRD-K97309399-001-09-4': 988, 'BRD-K97428065-001-01-2': 989, 'BRD-K97472745-001-01-8': 990, 'BRD-K97564742-050-32-7': 991, 'BRD-K97688263-001-03-7': 992, 'BRD-K97729603-001-01-2': 993, 'BRD-K97746869-001-27-0': 994, 'BRD-K97799481-001-16-0': 995, 'BRD-K97884852-001-05-4': 996, 'BRD-K97963946-001-01-3': 997, 'BRD-K98453471-001-01-7': 998, 'BRD-K98493452-001-14-9': 999, 'BRD-K98530306-003-18-3': 1000, 'BRD-K98572433-001-02-9': 1001, 'BRD-K98624455-074-02-8': 1002, 'BRD-K98769987-001-23-7': 1003, 'BRD-K99023089-001-03-7': 1004, 'BRD-K99092662-001-01-1': 1005, 'BRD-K99107520-001-24-1': 1006, 'BRD-K99113996-001-02-0': 1007, 'BRD-K99257182-310-01-6': 1008, 'BRD-K99383816-001-02-7': 1009, 'BRD-K99451608-001-07-3': 1010, 'BRD-K99475619-001-01-2': 1011, 'BRD-K99504665-001-01-2': 1012, 'BRD-K99545815-001-06-3': 1013, 'BRD-K99604664-001-01-1': 1014, 'BRD-K99749624-001-07-0': 1015, 'BRD-K99792991-001-34-9': 1016, 'DMSO': 1017}
                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
 >> Shuffling training sample with 574288 examples
 >> Number of classes: 1144
                    Compound  Key
0     BRD-A00218260-001-03-4   29
1     BRD-A00376169-001-01-6   31
2     BRD-A00546892-001-02-6   37
3     BRD-A00938334-001-01-3   35
4     BRD-A01636364-003-15-1   23
...                      ...  ...
1139  BRD-K99545815-001-06-3   36
1140  BRD-K99604664-001-01-1   28
1141  BRD-K99749624-001-07-0   13
1142  BRD-K99792991-001-34-9   14
1143                    DMSO  112

[1144 rows x 2 columns]
BRD-K19741547-003-01-7    13
BRD-K32107296-001-16-9    12
BRD-K68870568-066-01-5    11
BRD-K84564571-001-02-4    11
BRD-K56343971-001-10-6    11
                          ..
BRD-A21858158-001-23-5     1
BRD-K32977963-001-05-0     1
BRD-K87782578-001-01-4     1
BRD-K56104152-008-04-1     1
BRD-K50938287-036-13-8     1
Name: Compound, Length: 1135, dtype: int64
 >> Number of classes: 1144
2021-11-02 22:07:20,632 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:602: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
2021-11-02 22:07:20,961 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:535: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with distribution=normal is deprecated and will be removed in a future version.
Instructions for updating:
`normal` is a deprecated alias for `truncated_normal`
2021-11-02 22:07:21,006 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2021-11-02 22:07:23,519 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-11-02 22:07:23,520 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-11-02 22:07:23,521 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-11-02 22:07:23,788 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 5) 0
__________________________________________________________________________________________________
augmentation_layer (Augmentatio (None, 128, 128, 5)  0           input_1[0][0]
__________________________________________________________________________________________________
stem_conv (Conv2D)              (None, 64, 64, 32)   1440        augmentation_layer[0][0]
__________________________________________________________________________________________________
stem_bn (BatchNormalization)    (None, 64, 64, 32)   128         stem_conv[0][0]
__________________________________________________________________________________________________
stem_activation (Activation)    (None, 64, 64, 32)   0           stem_bn[0][0]
__________________________________________________________________________________________________
block1a_dwconv (DepthwiseConv2D (None, 64, 64, 32)   288         stem_activation[0][0]
__________________________________________________________________________________________________
block1a_bn (BatchNormalization) (None, 64, 64, 32)   128         block1a_dwconv[0][0]
__________________________________________________________________________________________________
block1a_activation (Activation) (None, 64, 64, 32)   0           block1a_bn[0][0]
__________________________________________________________________________________________________
block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]
__________________________________________________________________________________________________
block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]
__________________________________________________________________________________________________
block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]
__________________________________________________________________________________________________
block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]
__________________________________________________________________________________________________
block1a_se_excite (Multiply)    (None, 64, 64, 32)   0           block1a_activation[0][0]
                                                                 block1a_se_expand[0][0]
__________________________________________________________________________________________________
block1a_project_conv (Conv2D)   (None, 64, 64, 16)   512         block1a_se_excite[0][0]
__________________________________________________________________________________________________
block1a_project_bn (BatchNormal (None, 64, 64, 16)   64          block1a_project_conv[0][0]
__________________________________________________________________________________________________
block2a_expand_conv (Conv2D)    (None, 64, 64, 96)   1536        block1a_project_bn[0][0]
__________________________________________________________________________________________________
block2a_expand_bn (BatchNormali (None, 64, 64, 96)   384         block2a_expand_conv[0][0]
__________________________________________________________________________________________________
block2a_expand_activation (Acti (None, 64, 64, 96)   0           block2a_expand_bn[0][0]
__________________________________________________________________________________________________
block2a_dwconv (DepthwiseConv2D (None, 32, 32, 96)   864         block2a_expand_activation[0][0]
__________________________________________________________________________________________________
block2a_bn (BatchNormalization) (None, 32, 32, 96)   384         block2a_dwconv[0][0]
__________________________________________________________________________________________________
block2a_activation (Activation) (None, 32, 32, 96)   0           block2a_bn[0][0]
__________________________________________________________________________________________________
block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]
__________________________________________________________________________________________________
block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]
__________________________________________________________________________________________________
block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]
__________________________________________________________________________________________________
block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]
__________________________________________________________________________________________________
block2a_se_excite (Multiply)    (None, 32, 32, 96)   0           block2a_activation[0][0]
                                                                 block2a_se_expand[0][0]
__________________________________________________________________________________________________
block2a_project_conv (Conv2D)   (None, 32, 32, 24)   2304        block2a_se_excite[0][0]
__________________________________________________________________________________________________
block2a_project_bn (BatchNormal (None, 32, 32, 24)   96          block2a_project_conv[0][0]
__________________________________________________________________________________________________
block2b_expand_conv (Conv2D)    (None, 32, 32, 144)  3456        block2a_project_bn[0][0]
__________________________________________________________________________________________________
block2b_expand_bn (BatchNormali (None, 32, 32, 144)  576         block2b_expand_conv[0][0]
__________________________________________________________________________________________________
block2b_expand_activation (Acti (None, 32, 32, 144)  0           block2b_expand_bn[0][0]
__________________________________________________________________________________________________
block2b_dwconv (DepthwiseConv2D (None, 32, 32, 144)  1296        block2b_expand_activation[0][0]
__________________________________________________________________________________________________
block2b_bn (BatchNormalization) (None, 32, 32, 144)  576         block2b_dwconv[0][0]
__________________________________________________________________________________________________
block2b_activation (Activation) (None, 32, 32, 144)  0           block2b_bn[0][0]
__________________________________________________________________________________________________
block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]
__________________________________________________________________________________________________
block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]
__________________________________________________________________________________________________
block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]
__________________________________________________________________________________________________
block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]
__________________________________________________________________________________________________
block2b_se_excite (Multiply)    (None, 32, 32, 144)  0           block2b_activation[0][0]
                                                                 block2b_se_expand[0][0]
__________________________________________________________________________________________________
block2b_project_conv (Conv2D)   (None, 32, 32, 24)   3456        block2b_se_excite[0][0]
__________________________________________________________________________________________________
block2b_project_bn (BatchNormal (None, 32, 32, 24)   96          block2b_project_conv[0][0]
__________________________________________________________________________________________________
block2b_drop (FixedDropout)     (None, 32, 32, 24)   0           block2b_project_bn[0][0]
__________________________________________________________________________________________________
block2b_add (Add)               (None, 32, 32, 24)   0           block2b_drop[0][0]
                                                                 block2a_project_bn[0][0]
__________________________________________________________________________________________________
block3a_expand_conv (Conv2D)    (None, 32, 32, 144)  3456        block2b_add[0][0]
__________________________________________________________________________________________________
block3a_expand_bn (BatchNormali (None, 32, 32, 144)  576         block3a_expand_conv[0][0]
__________________________________________________________________________________________________
block3a_expand_activation (Acti (None, 32, 32, 144)  0           block3a_expand_bn[0][0]
__________________________________________________________________________________________________
block3a_dwconv (DepthwiseConv2D (None, 16, 16, 144)  3600        block3a_expand_activation[0][0]
__________________________________________________________________________________________________
block3a_bn (BatchNormalization) (None, 16, 16, 144)  576         block3a_dwconv[0][0]
__________________________________________________________________________________________________
block3a_activation (Activation) (None, 16, 16, 144)  0           block3a_bn[0][0]
__________________________________________________________________________________________________
block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]
__________________________________________________________________________________________________
block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]
__________________________________________________________________________________________________
block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]
__________________________________________________________________________________________________
block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]
__________________________________________________________________________________________________
block3a_se_excite (Multiply)    (None, 16, 16, 144)  0           block3a_activation[0][0]
                                                                 block3a_se_expand[0][0]
__________________________________________________________________________________________________
block3a_project_conv (Conv2D)   (None, 16, 16, 40)   5760        block3a_se_excite[0][0]
__________________________________________________________________________________________________
block3a_project_bn (BatchNormal (None, 16, 16, 40)   160         block3a_project_conv[0][0]
__________________________________________________________________________________________________
block3b_expand_conv (Conv2D)    (None, 16, 16, 240)  9600        block3a_project_bn[0][0]
__________________________________________________________________________________________________
block3b_expand_bn (BatchNormali (None, 16, 16, 240)  960         block3b_expand_conv[0][0]
__________________________________________________________________________________________________
block3b_expand_activation (Acti (None, 16, 16, 240)  0           block3b_expand_bn[0][0]
__________________________________________________________________________________________________
block3b_dwconv (DepthwiseConv2D (None, 16, 16, 240)  6000        block3b_expand_activation[0][0]
__________________________________________________________________________________________________
block3b_bn (BatchNormalization) (None, 16, 16, 240)  960         block3b_dwconv[0][0]
__________________________________________________________________________________________________
block3b_activation (Activation) (None, 16, 16, 240)  0           block3b_bn[0][0]
__________________________________________________________________________________________________
block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]
__________________________________________________________________________________________________
block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]
__________________________________________________________________________________________________
block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]
__________________________________________________________________________________________________
block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]
__________________________________________________________________________________________________
block3b_se_excite (Multiply)    (None, 16, 16, 240)  0           block3b_activation[0][0]
                                                                 block3b_se_expand[0][0]
__________________________________________________________________________________________________
block3b_project_conv (Conv2D)   (None, 16, 16, 40)   9600        block3b_se_excite[0][0]
__________________________________________________________________________________________________
block3b_project_bn (BatchNormal (None, 16, 16, 40)   160         block3b_project_conv[0][0]
__________________________________________________________________________________________________
block3b_drop (FixedDropout)     (None, 16, 16, 40)   0           block3b_project_bn[0][0]
__________________________________________________________________________________________________
block3b_add (Add)               (None, 16, 16, 40)   0           block3b_drop[0][0]
                                                                 block3a_project_bn[0][0]
__________________________________________________________________________________________________
block4a_expand_conv (Conv2D)    (None, 16, 16, 240)  9600        block3b_add[0][0]
__________________________________________________________________________________________________
block4a_expand_bn (BatchNormali (None, 16, 16, 240)  960         block4a_expand_conv[0][0]
__________________________________________________________________________________________________
block4a_expand_activation (Acti (None, 16, 16, 240)  0           block4a_expand_bn[0][0]
__________________________________________________________________________________________________
block4a_dwconv (DepthwiseConv2D (None, 8, 8, 240)    2160        block4a_expand_activation[0][0]
__________________________________________________________________________________________________
block4a_bn (BatchNormalization) (None, 8, 8, 240)    960         block4a_dwconv[0][0]
__________________________________________________________________________________________________
block4a_activation (Activation) (None, 8, 8, 240)    0           block4a_bn[0][0]
__________________________________________________________________________________________________
block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]
__________________________________________________________________________________________________
block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]
__________________________________________________________________________________________________
block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]
__________________________________________________________________________________________________
block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]
__________________________________________________________________________________________________
block4a_se_excite (Multiply)    (None, 8, 8, 240)    0           block4a_activation[0][0]
                                                                 block4a_se_expand[0][0]
__________________________________________________________________________________________________
block4a_project_conv (Conv2D)   (None, 8, 8, 80)     19200       block4a_se_excite[0][0]
__________________________________________________________________________________________________
block4a_project_bn (BatchNormal (None, 8, 8, 80)     320         block4a_project_conv[0][0]
__________________________________________________________________________________________________
block4b_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4a_project_bn[0][0]
__________________________________________________________________________________________________
block4b_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4b_expand_conv[0][0]
__________________________________________________________________________________________________
block4b_expand_activation (Acti (None, 8, 8, 480)    0           block4b_expand_bn[0][0]
__________________________________________________________________________________________________
block4b_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4b_expand_activation[0][0]
__________________________________________________________________________________________________
block4b_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4b_dwconv[0][0]
__________________________________________________________________________________________________
block4b_activation (Activation) (None, 8, 8, 480)    0           block4b_bn[0][0]
__________________________________________________________________________________________________
block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]
__________________________________________________________________________________________________
block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]
__________________________________________________________________________________________________
block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]
__________________________________________________________________________________________________
block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]
__________________________________________________________________________________________________
block4b_se_excite (Multiply)    (None, 8, 8, 480)    0           block4b_activation[0][0]
                                                                 block4b_se_expand[0][0]
__________________________________________________________________________________________________
block4b_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4b_se_excite[0][0]
__________________________________________________________________________________________________
block4b_project_bn (BatchNormal (None, 8, 8, 80)     320         block4b_project_conv[0][0]
__________________________________________________________________________________________________
block4b_drop (FixedDropout)     (None, 8, 8, 80)     0           block4b_project_bn[0][0]
__________________________________________________________________________________________________
block4b_add (Add)               (None, 8, 8, 80)     0           block4b_drop[0][0]
                                                                 block4a_project_bn[0][0]
__________________________________________________________________________________________________
block4c_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4b_add[0][0]
__________________________________________________________________________________________________
block4c_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4c_expand_conv[0][0]
__________________________________________________________________________________________________
block4c_expand_activation (Acti (None, 8, 8, 480)    0           block4c_expand_bn[0][0]
__________________________________________________________________________________________________
block4c_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4c_expand_activation[0][0]
__________________________________________________________________________________________________
block4c_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4c_dwconv[0][0]
__________________________________________________________________________________________________
block4c_activation (Activation) (None, 8, 8, 480)    0           block4c_bn[0][0]
__________________________________________________________________________________________________
block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]
__________________________________________________________________________________________________
block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]
__________________________________________________________________________________________________
block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]
__________________________________________________________________________________________________
block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]
__________________________________________________________________________________________________
block4c_se_excite (Multiply)    (None, 8, 8, 480)    0           block4c_activation[0][0]
                                                                 block4c_se_expand[0][0]
__________________________________________________________________________________________________
block4c_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4c_se_excite[0][0]
__________________________________________________________________________________________________
block4c_project_bn (BatchNormal (None, 8, 8, 80)     320         block4c_project_conv[0][0]
__________________________________________________________________________________________________
block4c_drop (FixedDropout)     (None, 8, 8, 80)     0           block4c_project_bn[0][0]
__________________________________________________________________________________________________
block4c_add (Add)               (None, 8, 8, 80)     0           block4c_drop[0][0]
                                                                 block4b_add[0][0]
__________________________________________________________________________________________________
block5a_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4c_add[0][0]
__________________________________________________________________________________________________
block5a_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block5a_expand_conv[0][0]
__________________________________________________________________________________________________
block5a_expand_activation (Acti (None, 8, 8, 480)    0           block5a_expand_bn[0][0]
__________________________________________________________________________________________________
block5a_dwconv (DepthwiseConv2D (None, 8, 8, 480)    12000       block5a_expand_activation[0][0]
__________________________________________________________________________________________________
block5a_bn (BatchNormalization) (None, 8, 8, 480)    1920        block5a_dwconv[0][0]
__________________________________________________________________________________________________
block5a_activation (Activation) (None, 8, 8, 480)    0           block5a_bn[0][0]
__________________________________________________________________________________________________
block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]
__________________________________________________________________________________________________
block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]
__________________________________________________________________________________________________
block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]
__________________________________________________________________________________________________
block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]
__________________________________________________________________________________________________
block5a_se_excite (Multiply)    (None, 8, 8, 480)    0           block5a_activation[0][0]
                                                                 block5a_se_expand[0][0]
__________________________________________________________________________________________________
block5a_project_conv (Conv2D)   (None, 8, 8, 112)    53760       block5a_se_excite[0][0]
__________________________________________________________________________________________________
block5a_project_bn (BatchNormal (None, 8, 8, 112)    448         block5a_project_conv[0][0]
__________________________________________________________________________________________________
block5b_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5a_project_bn[0][0]
__________________________________________________________________________________________________
block5b_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5b_expand_conv[0][0]
__________________________________________________________________________________________________
block5b_expand_activation (Acti (None, 8, 8, 672)    0           block5b_expand_bn[0][0]
__________________________________________________________________________________________________
block5b_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5b_expand_activation[0][0]
__________________________________________________________________________________________________
block5b_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5b_dwconv[0][0]
__________________________________________________________________________________________________
block5b_activation (Activation) (None, 8, 8, 672)    0           block5b_bn[0][0]
__________________________________________________________________________________________________
block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]
__________________________________________________________________________________________________
block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]
__________________________________________________________________________________________________
block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]
__________________________________________________________________________________________________
block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]
__________________________________________________________________________________________________
block5b_se_excite (Multiply)    (None, 8, 8, 672)    0           block5b_activation[0][0]
                                                                 block5b_se_expand[0][0]
__________________________________________________________________________________________________
block5b_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5b_se_excite[0][0]
__________________________________________________________________________________________________
block5b_project_bn (BatchNormal (None, 8, 8, 112)    448         block5b_project_conv[0][0]
__________________________________________________________________________________________________
block5b_drop (FixedDropout)     (None, 8, 8, 112)    0           block5b_project_bn[0][0]
__________________________________________________________________________________________________
block5b_add (Add)               (None, 8, 8, 112)    0           block5b_drop[0][0]
                                                                 block5a_project_bn[0][0]
__________________________________________________________________________________________________
block5c_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5b_add[0][0]
__________________________________________________________________________________________________
block5c_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5c_expand_conv[0][0]
__________________________________________________________________________________________________
block5c_expand_activation (Acti (None, 8, 8, 672)    0           block5c_expand_bn[0][0]
__________________________________________________________________________________________________
block5c_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5c_expand_activation[0][0]
__________________________________________________________________________________________________
block5c_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5c_dwconv[0][0]
__________________________________________________________________________________________________
block5c_activation (Activation) (None, 8, 8, 672)    0           block5c_bn[0][0]
__________________________________________________________________________________________________
block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]
__________________________________________________________________________________________________
block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]
__________________________________________________________________________________________________
block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]
__________________________________________________________________________________________________
block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]
__________________________________________________________________________________________________
block5c_se_excite (Multiply)    (None, 8, 8, 672)    0           block5c_activation[0][0]
                                                                 block5c_se_expand[0][0]
__________________________________________________________________________________________________
block5c_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5c_se_excite[0][0]
__________________________________________________________________________________________________
block5c_project_bn (BatchNormal (None, 8, 8, 112)    448         block5c_project_conv[0][0]
__________________________________________________________________________________________________
block5c_drop (FixedDropout)     (None, 8, 8, 112)    0           block5c_project_bn[0][0]
__________________________________________________________________________________________________
block5c_add (Add)               (None, 8, 8, 112)    0           block5c_drop[0][0]
                                                                 block5b_add[0][0]
__________________________________________________________________________________________________
block6a_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5c_add[0][0]
__________________________________________________________________________________________________
block6a_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block6a_expand_conv[0][0]
__________________________________________________________________________________________________
block6a_expand_activation (Acti (None, 8, 8, 672)    0           block6a_expand_bn[0][0]
__________________________________________________________________________________________________
block6a_dwconv (DepthwiseConv2D (None, 4, 4, 672)    16800       block6a_expand_activation[0][0]
__________________________________________________________________________________________________
block6a_bn (BatchNormalization) (None, 4, 4, 672)    2688        block6a_dwconv[0][0]
__________________________________________________________________________________________________
block6a_activation (Activation) (None, 4, 4, 672)    0           block6a_bn[0][0]
__________________________________________________________________________________________________
block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]
__________________________________________________________________________________________________
block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]
__________________________________________________________________________________________________
block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]
__________________________________________________________________________________________________
block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]
__________________________________________________________________________________________________
block6a_se_excite (Multiply)    (None, 4, 4, 672)    0           block6a_activation[0][0]
                                                                 block6a_se_expand[0][0]
__________________________________________________________________________________________________
block6a_project_conv (Conv2D)   (None, 4, 4, 192)    129024      block6a_se_excite[0][0]
__________________________________________________________________________________________________
block6a_project_bn (BatchNormal (None, 4, 4, 192)    768         block6a_project_conv[0][0]
__________________________________________________________________________________________________
block6b_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6a_project_bn[0][0]
__________________________________________________________________________________________________
block6b_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6b_expand_conv[0][0]
__________________________________________________________________________________________________
block6b_expand_activation (Acti (None, 4, 4, 1152)   0           block6b_expand_bn[0][0]
__________________________________________________________________________________________________
block6b_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6b_expand_activation[0][0]
__________________________________________________________________________________________________
block6b_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6b_dwconv[0][0]
__________________________________________________________________________________________________
block6b_activation (Activation) (None, 4, 4, 1152)   0           block6b_bn[0][0]
__________________________________________________________________________________________________
block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]
__________________________________________________________________________________________________
block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]
__________________________________________________________________________________________________
block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]
__________________________________________________________________________________________________
block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]
__________________________________________________________________________________________________
block6b_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6b_activation[0][0]
                                                                 block6b_se_expand[0][0]
__________________________________________________________________________________________________
block6b_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6b_se_excite[0][0]
__________________________________________________________________________________________________
block6b_project_bn (BatchNormal (None, 4, 4, 192)    768         block6b_project_conv[0][0]
__________________________________________________________________________________________________
block6b_drop (FixedDropout)     (None, 4, 4, 192)    0           block6b_project_bn[0][0]
__________________________________________________________________________________________________
block6b_add (Add)               (None, 4, 4, 192)    0           block6b_drop[0][0]
                                                                 block6a_project_bn[0][0]
__________________________________________________________________________________________________
block6c_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6b_add[0][0]
__________________________________________________________________________________________________
block6c_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6c_expand_conv[0][0]
__________________________________________________________________________________________________
block6c_expand_activation (Acti (None, 4, 4, 1152)   0           block6c_expand_bn[0][0]
__________________________________________________________________________________________________
block6c_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6c_expand_activation[0][0]
__________________________________________________________________________________________________
block6c_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6c_dwconv[0][0]
__________________________________________________________________________________________________
block6c_activation (Activation) (None, 4, 4, 1152)   0           block6c_bn[0][0]
__________________________________________________________________________________________________
block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]
__________________________________________________________________________________________________
block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]
__________________________________________________________________________________________________
block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]
__________________________________________________________________________________________________
block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]
__________________________________________________________________________________________________
block6c_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6c_activation[0][0]
                                                                 block6c_se_expand[0][0]          2021-11-02 22:07:26.720641: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-02 22:07:26.756012: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-11-02 22:07:26.860058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-11-02 22:07:26.860187: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 22:07:26.863900: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-11-02 22:07:26.864108: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-11-02 22:07:26.865624: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-11-02 22:07:26.865933: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-11-02 22:07:26.866942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2021-11-02 22:07:26.867814: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-11-02 22:07:26.868175: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-11-02 22:07:26.872000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-11-02 22:07:26.872074: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-11-02 22:07:27.429168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-11-02 22:07:27.429237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0
2021-11-02 22:07:27.429253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N
2021-11-02 22:07:27.434806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38423 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0)

__________________________________________________________________________________________________
block6c_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6c_se_excite[0][0]
__________________________________________________________________________________________________
block6c_project_bn (BatchNormal (None, 4, 4, 192)    768         block6c_project_conv[0][0]
__________________________________________________________________________________________________
block6c_drop (FixedDropout)     (None, 4, 4, 192)    0           block6c_project_bn[0][0]
__________________________________________________________________________________________________
block6c_add (Add)               (None, 4, 4, 192)    0           block6c_drop[0][0]
                                                                 block6b_add[0][0]
__________________________________________________________________________________________________
block6d_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6c_add[0][0]
__________________________________________________________________________________________________
block6d_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6d_expand_conv[0][0]
__________________________________________________________________________________________________
block6d_expand_activation (Acti (None, 4, 4, 1152)   0           block6d_expand_bn[0][0]
__________________________________________________________________________________________________
block6d_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6d_expand_activation[0][0]
__________________________________________________________________________________________________
block6d_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6d_dwconv[0][0]
__________________________________________________________________________________________________
block6d_activation (Activation) (None, 4, 4, 1152)   0           block6d_bn[0][0]
__________________________________________________________________________________________________
block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]
__________________________________________________________________________________________________
block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]
__________________________________________________________________________________________________
block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]
__________________________________________________________________________________________________
block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]
__________________________________________________________________________________________________
block6d_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6d_activation[0][0]
                                                                 block6d_se_expand[0][0]
__________________________________________________________________________________________________
block6d_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6d_se_excite[0][0]
__________________________________________________________________________________________________
block6d_project_bn (BatchNormal (None, 4, 4, 192)    768         block6d_project_conv[0][0]
__________________________________________________________________________________________________
block6d_drop (FixedDropout)     (None, 4, 4, 192)    0           block6d_project_bn[0][0]
__________________________________________________________________________________________________
block6d_add (Add)               (None, 4, 4, 192)    0           block6d_drop[0][0]
                                                                 block6c_add[0][0]
__________________________________________________________________________________________________
block7a_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6d_add[0][0]
__________________________________________________________________________________________________
block7a_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block7a_expand_conv[0][0]
__________________________________________________________________________________________________
block7a_expand_activation (Acti (None, 4, 4, 1152)   0           block7a_expand_bn[0][0]
__________________________________________________________________________________________________
block7a_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   10368       block7a_expand_activation[0][0]
__________________________________________________________________________________________________
block7a_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block7a_dwconv[0][0]
__________________________________________________________________________________________________
block7a_activation (Activation) (None, 4, 4, 1152)   0           block7a_bn[0][0]
__________________________________________________________________________________________________
block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]
__________________________________________________________________________________________________
block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]
__________________________________________________________________________________________________
block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]
__________________________________________________________________________________________________
block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]
__________________________________________________________________________________________________
block7a_se_excite (Multiply)    (None, 4, 4, 1152)   0           block7a_activation[0][0]
                                                                 block7a_se_expand[0][0]
__________________________________________________________________________________________________
block7a_project_conv (Conv2D)   (None, 4, 4, 320)    368640      block7a_se_excite[0][0]
__________________________________________________________________________________________________
block7a_project_bn (BatchNormal (None, 4, 4, 320)    1280        block7a_project_conv[0][0]
__________________________________________________________________________________________________
top_conv (Conv2D)               (None, 4, 4, 1280)   409600      block7a_project_bn[0][0]
__________________________________________________________________________________________________
top_bn (BatchNormalization)     (None, 4, 4, 1280)   5120        top_conv[0][0]
__________________________________________________________________________________________________
top_activation (Activation)     (None, 4, 4, 1280)   0           top_bn[0][0]
__________________________________________________________________________________________________
pool5 (GlobalAveragePooling2D)  (None, 1280)         0           top_activation[0][0]
__________________________________________________________________________________________________
ClassProb (Dense)               (None, 1144)         1465464     pool5[0][0]
==================================================================================================
Total params: 5,515,604
Trainable params: 5,473,588
Non-trainable params: 42,016
__________________________________________________________________________________________________
2021-11-02 22:07:27,706 - WARNING - From /DeepProfiler/deepprofiler/learning/model.py:143: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

2021-11-02 22:08:34.357863: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3200140000 Hz
Validation data: (5491, 128, 128, 5) (5491, 1144)
Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5
16809984/16804768 [==============================] - 3s 0us/step
Network initialized with pretrained ImageNet weights
2021-11-02 22:10:47,501 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
2021-11-02 22:11:03.998640: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-11-02 22:11:04.939210: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-11-02 22:11:05.512378: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-11-02 22:11:06.251989: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100
2021-11-02 22:11:07.633347: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.

Epoch 00001: LearningRateScheduler reducing learning rate to 0.008.
Epoch 1/30
8963/8974 [============================>.] - ETA: 2s - batch: 4481.0000 - size: 64.0000 - loss: 5.1505 - acc: 0.1153 - top_5: 0.2558                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8973/8974 [============================>.] - ETA: 0s - batch: 4486.0000 - size: 64.0000 - loss: 5.1492 - acc: 0.1154 - top_5: 0.2560 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2206s 244ms/step - batch: 4486.5000 - size: 64.0000 - loss: 5.1491 - acc: 0.1154 - top_5: 0.2560 - val_loss: 4.2842 - val_acc: 0.1788 - val_top_5: 0.3854 - lr: 0.0080

Epoch 00002: LearningRateScheduler reducing learning rate to 0.01.
Epoch 2/30
8962/8974 [============================>.] - ETA: 5s - batch: 4480.5000 - size: 64.0000 - loss: 3.5756 - acc: 0.2688 - top_5: 0.5054                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8972/8974 [============================>.] - ETA: 0s - batch: 4485.5000 - size: 64.0000 - loss: 3.5752 - acc: 0.2688 - top_5: 0.5055 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 4337s 483ms/step - batch: 4486.5000 - size: 64.0000 - loss: 3.5751 - acc: 0.2689 - top_5: 0.5055 - val_loss: 3.8124 - val_acc: 0.2519 - val_top_5: 0.4804 - lr: 0.0100

Epoch 00003: LearningRateScheduler reducing learning rate to 0.013333333333333334.
Epoch 3/30
8961/8974 [============================>.] - ETA: 10s - batch: 4480.0000 - size: 64.0000 - loss: 3.1115 - acc: 0.3405 - top_5: 0.5970                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8971/8974 [============================>.] - ETA: 2s - batch: 4485.0000 - size: 64.0000 - loss: 3.1114 - acc: 0.3405 - top_5: 0.5970 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 7400s 825ms/step - batch: 4486.5000 - size: 64.0000 - loss: 3.1112 - acc: 0.3405 - top_5: 0.5971 - val_loss: 3.3524 - val_acc: 0.3016 - val_top_5: 0.5654 - lr: 0.0133

Epoch 00004: LearningRateScheduler reducing learning rate to 0.02.
Epoch 4/30
8961/8974 [============================>.] - ETA: 7s - batch: 4480.0000 - size: 64.0000 - loss: 2.8934 - acc: 0.3800 - top_5: 0.6443                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8971/8974 [============================>.] - ETA: 1s - batch: 4485.0000 - size: 64.0000 - loss: 2.8932 - acc: 0.3800 - top_5: 0.6444 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 4918s 548ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.8931 - acc: 0.3801 - top_5: 0.6444 - val_loss: 3.4765 - val_acc: 0.2919 - val_top_5: 0.5494 - lr: 0.0200

Epoch 00005: LearningRateScheduler reducing learning rate to 0.04.
Epoch 5/30
8959/8974 [============================>.] - ETA: 8s - batch: 4479.0000 - size: 64.0000 - loss: 2.9380 - acc: 0.3799 - top_5: 0.6475                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8970/8974 [============================>.] - ETA: 2s - batch: 4484.5000 - size: 64.0000 - loss: 2.9377 - acc: 0.3800 - top_5: 0.6476 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 5344s 595ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.9374 - acc: 0.3800 - top_5: 0.6476 - val_loss: 4.0092 - val_acc: 0.2561 - val_top_5: 0.4938 - lr: 0.0400

Epoch 00006: LearningRateScheduler reducing learning rate to 0.03732050807568878.
Epoch 6/30
8959/8974 [============================>.] - ETA: 9s - batch: 4479.0000 - size: 64.0000 - loss: 2.5905 - acc: 0.4527 - top_5: 0.7199                     Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8969/8974 [============================>.] - ETA: 3s - batch: 4484.0000 - size: 64.0000 - loss: 2.5903 - acc: 0.4528 - top_5: 0.7200 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 5837s 650ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.5902 - acc: 0.4528 - top_5: 0.7200 - val_loss: 3.5167 - val_acc: 0.3318 - val_top_5: 0.5888 - lr: 0.0373

Epoch 00007: LearningRateScheduler reducing learning rate to 0.03618033988749895.
Epoch 7/30
8959/8974 [============================>.] - ETA: 12s - batch: 4479.0000 - size: 64.0000 - loss: 2.4032 - acc: 0.4956 - top_5: 0.7590                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8968/8974 [============================>.] - ETA: 5s - batch: 4483.5000 - size: 64.0000 - loss: 2.4032 - acc: 0.4956 - top_5: 0.7591 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 7528s 839ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.4032 - acc: 0.4956 - top_5: 0.7591 - val_loss: 3.4782 - val_acc: 0.3213 - val_top_5: 0.5883 - lr: 0.0362

Epoch 00008: LearningRateScheduler reducing learning rate to 0.03486289650954789.
Epoch 8/30
8958/8974 [============================>.] - ETA: 4s - batch: 4478.5000 - size: 64.0000 - loss: 2.2671 - acc: 0.5282 - top_5: 0.7876                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8968/8974 [============================>.] - ETA: 1s - batch: 4483.5000 - size: 64.0000 - loss: 2.2669 - acc: 0.5282 - top_5: 0.7877 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2781s 310ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.2668 - acc: 0.5282 - top_5: 0.7877 - val_loss: 3.1211 - val_acc: 0.3861 - val_top_5: 0.6531 - lr: 0.0349

Epoch 00009: LearningRateScheduler reducing learning rate to 0.033382612127177164.
Epoch 9/30
8957/8974 [============================>.] - ETA: 4s - batch: 4478.0000 - size: 64.0000 - loss: 2.1558 - acc: 0.5554 - top_5: 0.8090                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8967/8974 [============================>.] - ETA: 2s - batch: 4483.0000 - size: 64.0000 - loss: 2.1558 - acc: 0.5554 - top_5: 0.8091 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2645s 295ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.1557 - acc: 0.5555 - top_5: 0.8091 - val_loss: 3.2607 - val_acc: 0.3724 - val_top_5: 0.6441 - lr: 0.0334

Epoch 00010: LearningRateScheduler reducing learning rate to 0.031755705045849465.
Epoch 10/30
8956/8974 [============================>.] - ETA: 4s - batch: 4477.5000 - size: 64.0000 - loss: 2.0593 - acc: 0.5784 - top_5: 0.8295                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8966/8974 [============================>.] - ETA: 2s - batch: 4482.5000 - size: 64.0000 - loss: 2.0594 - acc: 0.5783 - top_5: 0.8295 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2457s 274ms/step - batch: 4486.5000 - size: 64.0000 - loss: 2.0594 - acc: 0.5783 - top_5: 0.8295 - val_loss: 2.9204 - val_acc: 0.4247 - val_top_5: 0.6993 - lr: 0.0318

Epoch 00011: LearningRateScheduler reducing learning rate to 0.03.
Epoch 11/30
8955/8974 [============================>.] - ETA: 5s - batch: 4477.0000 - size: 64.0000 - loss: 1.9741 - acc: 0.6002 - top_5: 0.8438                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8965/8974 [============================>.] - ETA: 2s - batch: 4482.0000 - size: 64.0000 - loss: 1.9742 - acc: 0.6002 - top_5: 0.8438 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2483s 277ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.9740 - acc: 0.6003 - top_5: 0.8438 - val_loss: 2.9095 - val_acc: 0.4371 - val_top_5: 0.7092 - lr: 0.0300

Epoch 00012: LearningRateScheduler reducing learning rate to 0.028134732861516007.
Epoch 12/30
8954/8974 [============================>.] - ETA: 5s - batch: 4476.5000 - size: 64.0000 - loss: 1.8890 - acc: 0.6206 - top_5: 0.8584                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8965/8974 [============================>.] - ETA: 2s - batch: 4482.0000 - size: 64.0000 - loss: 1.8890 - acc: 0.6206 - top_5: 0.8584 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2615s 291ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.8890 - acc: 0.6206 - top_5: 0.8584 - val_loss: 2.7218 - val_acc: 0.4602 - val_top_5: 0.7396 - lr: 0.0281

Epoch 00013: LearningRateScheduler reducing learning rate to 0.02618033988749895.
Epoch 13/30
8954/8974 [============================>.] - ETA: 5s - batch: 4476.5000 - size: 64.0000 - loss: 1.8139 - acc: 0.6380 - top_5: 0.8707                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8964/8974 [============================>.] - ETA: 2s - batch: 4481.5000 - size: 64.0000 - loss: 1.8140 - acc: 0.6380 - top_5: 0.8707 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2495s 278ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.8139 - acc: 0.6380 - top_5: 0.8707 - val_loss: 2.6740 - val_acc: 0.4790 - val_top_5: 0.7483 - lr: 0.0262

Epoch 00014: LearningRateScheduler reducing learning rate to 0.024158233816355183.
Epoch 14/30
8953/8974 [============================>.] - ETA: 4s - batch: 4476.0000 - size: 64.0000 - loss: 1.7377 - acc: 0.6568 - top_5: 0.8834                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8963/8974 [============================>.] - ETA: 2s - batch: 4481.0000 - size: 64.0000 - loss: 1.7378 - acc: 0.6568 - top_5: 0.8834 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2131s 237ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.7377 - acc: 0.6568 - top_5: 0.8834 - val_loss: 2.7751 - val_acc: 0.4600 - val_top_5: 0.7348 - lr: 0.0242

Epoch 00015: LearningRateScheduler reducing learning rate to 0.02209056926535307.
Epoch 15/30
8952/8974 [============================>.] - ETA: 5s - batch: 4475.5000 - size: 64.0000 - loss: 1.6617 - acc: 0.6748 - top_5: 0.8949                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8962/8974 [============================>.] - ETA: 2s - batch: 4480.5000 - size: 64.0000 - loss: 1.6617 - acc: 0.6748 - top_5: 0.8949 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2199s 245ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.6615 - acc: 0.6749 - top_5: 0.8950 - val_loss: 2.6457 - val_acc: 0.4821 - val_top_5: 0.7519 - lr: 0.0221

Epoch 00016: LearningRateScheduler reducing learning rate to 0.020000000000000004.
Epoch 16/30
8952/8974 [============================>.] - ETA: 5s - batch: 4475.5000 - size: 64.0000 - loss: 1.5846 - acc: 0.6936 - top_5: 0.9059                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8962/8974 [============================>.] - ETA: 2s - batch: 4480.5000 - size: 64.0000 - loss: 1.5847 - acc: 0.6936 - top_5: 0.9059 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2254s 251ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.5846 - acc: 0.6936 - top_5: 0.9059 - val_loss: 2.4971 - val_acc: 0.5103 - val_top_5: 0.7764 - lr: 0.0200

Epoch 00017: LearningRateScheduler reducing learning rate to 0.017909430734646934.
Epoch 17/30
8950/8974 [============================>.] - ETA: 13s - batch: 4474.5000 - size: 64.0000 - loss: 1.5099 - acc: 0.7116 - top_5: 0.9160                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8961/8974 [============================>.] - ETA: 7s - batch: 4480.0000 - size: 64.0000 - loss: 1.5098 - acc: 0.7117 - top_5: 0.9160 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 5096s 568ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.5097 - acc: 0.7117 - top_5: 0.9160 - val_loss: 2.6836 - val_acc: 0.4821 - val_top_5: 0.7601 - lr: 0.0179

Epoch 00018: LearningRateScheduler reducing learning rate to 0.01584176618364481.
Epoch 18/30
8950/8974 [============================>.] - ETA: 16s - batch: 4474.5000 - size: 64.0000 - loss: 1.4331 - acc: 0.7302 - top_5: 0.9259                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8960/8974 [============================>.] - ETA: 9s - batch: 4479.5000 - size: 64.0000 - loss: 1.4331 - acc: 0.7302 - top_5: 0.9259  >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 6381s 711ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.4331 - acc: 0.7302 - top_5: 0.9259 - val_loss: 2.4824 - val_acc: 0.5229 - val_top_5: 0.7868 - lr: 0.0158

Epoch 00019: LearningRateScheduler reducing learning rate to 0.013819660112501053.
Epoch 19/30
8949/8974 [============================>.] - ETA: 6s - batch: 4474.0000 - size: 64.0000 - loss: 1.3548 - acc: 0.7494 - top_5: 0.9355                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8959/8974 [============================>.] - ETA: 3s - batch: 4479.0000 - size: 64.0000 - loss: 1.3548 - acc: 0.7494 - top_5: 0.9355 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2264s 252ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.3547 - acc: 0.7494 - top_5: 0.9355 - val_loss: 2.4139 - val_acc: 0.5285 - val_top_5: 0.7956 - lr: 0.0138

Epoch 00020: LearningRateScheduler reducing learning rate to 0.011865267138483999.
Epoch 20/30
8949/8974 [============================>.] - ETA: 6s - batch: 4474.0000 - size: 64.0000 - loss: 1.2824 - acc: 0.7669 - top_5: 0.9440                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8959/8974 [============================>.] - ETA: 3s - batch: 4479.0000 - size: 64.0000 - loss: 1.2824 - acc: 0.7669 - top_5: 0.9440 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2418s 269ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.2824 - acc: 0.7669 - top_5: 0.9440 - val_loss: 2.3263 - val_acc: 0.5567 - val_top_5: 0.8160 - lr: 0.0119

Epoch 00021: LearningRateScheduler reducing learning rate to 0.010000000000000005.
Epoch 21/30
8948/8974 [============================>.] - ETA: 6s - batch: 4473.5000 - size: 64.0000 - loss: 1.2051 - acc: 0.7872 - top_5: 0.9521                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8958/8974 [============================>.] - ETA: 4s - batch: 4478.5000 - size: 64.0000 - loss: 1.2051 - acc: 0.7872 - top_5: 0.9521 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2380s 265ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.2051 - acc: 0.7872 - top_5: 0.9521 - val_loss: 2.2990 - val_acc: 0.5644 - val_top_5: 0.8182 - lr: 0.0100

Epoch 00022: LearningRateScheduler reducing learning rate to 0.008244294954150539.
Epoch 22/30
8947/8974 [============================>.] - ETA: 7s - batch: 4473.0000 - size: 64.0000 - loss: 1.1337 - acc: 0.8057 - top_5: 0.9595                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8957/8974 [============================>.] - ETA: 4s - batch: 4478.0000 - size: 64.0000 - loss: 1.1338 - acc: 0.8056 - top_5: 0.9595 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2445s 272ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.1336 - acc: 0.8057 - top_5: 0.9595 - val_loss: 2.1542 - val_acc: 0.5808 - val_top_5: 0.8363 - lr: 0.0082

Epoch 00023: LearningRateScheduler reducing learning rate to 0.006617387872822842.
Epoch 23/30
8946/8974 [============================>.] - ETA: 7s - batch: 4472.5000 - size: 64.0000 - loss: 1.0655 - acc: 0.8240 - top_5: 0.9661                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8956/8974 [============================>.] - ETA: 4s - batch: 4477.5000 - size: 64.0000 - loss: 1.0655 - acc: 0.8240 - top_5: 0.9661 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2453s 273ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.0655 - acc: 0.8241 - top_5: 0.9661 - val_loss: 2.1526 - val_acc: 0.5824 - val_top_5: 0.8367 - lr: 0.0066

Epoch 00024: LearningRateScheduler reducing learning rate to 0.0051371034904521195.
Epoch 24/30
8946/8974 [============================>.] - ETA: 7s - batch: 4472.5000 - size: 64.0000 - loss: 1.0029 - acc: 0.8408 - top_5: 0.9720                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8956/8974 [============================>.] - ETA: 4s - batch: 4477.5000 - size: 64.0000 - loss: 1.0029 - acc: 0.8407 - top_5: 0.9720 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2351s 262ms/step - batch: 4486.5000 - size: 64.0000 - loss: 1.0028 - acc: 0.8408 - top_5: 0.9720 - val_loss: 2.0169 - val_acc: 0.6163 - val_top_5: 0.8518 - lr: 0.0051

Epoch 00025: LearningRateScheduler reducing learning rate to 0.003819660112501053.
Epoch 25/30
8945/8974 [============================>.] - ETA: 8s - batch: 4472.0000 - size: 64.0000 - loss: 0.9486 - acc: 0.8559 - top_5: 0.9764                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8955/8974 [============================>.] - ETA: 5s - batch: 4477.0000 - size: 64.0000 - loss: 0.9485 - acc: 0.8559 - top_5: 0.9764 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2562s 285ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.9485 - acc: 0.8559 - top_5: 0.9764 - val_loss: 2.0008 - val_acc: 0.6135 - val_top_5: 0.8641 - lr: 0.0038

Epoch 00026: LearningRateScheduler reducing learning rate to 0.002679491924311226.
Epoch 26/30
8944/8974 [============================>.] - ETA: 7s - batch: 4471.5000 - size: 64.0000 - loss: 0.9032 - acc: 0.8690 - top_5: 0.9801                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8954/8974 [============================>.] - ETA: 5s - batch: 4476.5000 - size: 64.0000 - loss: 0.9032 - acc: 0.8690 - top_5: 0.9801 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2417s 269ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.9032 - acc: 0.8690 - top_5: 0.9801 - val_loss: 1.9706 - val_acc: 0.6254 - val_top_5: 0.8639 - lr: 0.0027

Epoch 00027: LearningRateScheduler reducing learning rate to 0.0017290908471479804.
Epoch 27/30
8944/8974 [============================>.] - ETA: 7s - batch: 4471.5000 - size: 64.0000 - loss: 0.8688 - acc: 0.8791 - top_5: 0.9826                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8953/8974 [============================>.] - ETA: 5s - batch: 4476.0000 - size: 64.0000 - loss: 0.8687 - acc: 0.8791 - top_5: 0.9826 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2342s 261ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.8688 - acc: 0.8791 - top_5: 0.9826 - val_loss: 1.9213 - val_acc: 0.6361 - val_top_5: 0.8740 - lr: 0.0017

Epoch 00028: LearningRateScheduler reducing learning rate to 0.0009788696740969294.
Epoch 28/30
8943/8974 [============================>.] - ETA: 7s - batch: 4471.0000 - size: 64.0000 - loss: 0.8429 - acc: 0.8871 - top_5: 0.9845                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8953/8974 [============================>.] - ETA: 5s - batch: 4476.0000 - size: 64.0000 - loss: 0.8430 - acc: 0.8871 - top_5: 0.9845 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2338s 260ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.8431 - acc: 0.8871 - top_5: 0.9844 - val_loss: 1.9048 - val_acc: 0.6383 - val_top_5: 0.8702 - lr: 9.7887e-04

Epoch 00029: LearningRateScheduler reducing learning rate to 0.0004370479853238862.
Epoch 29/30
8942/8974 [============================>.] - ETA: 8s - batch: 4470.5000 - size: 64.0000 - loss: 0.8255 - acc: 0.8927 - top_5: 0.9856                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8952/8974 [============================>.] - ETA: 5s - batch: 4475.5000 - size: 64.0000 - loss: 0.8254 - acc: 0.8927 - top_5: 0.9856 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2362s 263ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.8255 - acc: 0.8927 - top_5: 0.9856 - val_loss: 1.9204 - val_acc: 0.6390 - val_top_5: 0.8707 - lr: 4.3705e-04

Epoch 00030: LearningRateScheduler reducing learning rate to 0.00010956209263453198.
Epoch 30/30
8941/8974 [============================>.] - ETA: 8s - batch: 4470.0000 - size: 64.0000 - loss: 0.8179 - acc: 0.8946 - top_5: 0.9860                    Compound   Key
0     BRD-A00218260-001-03-4   305
1     BRD-A00376169-001-01-6   327
2     BRD-A00546892-001-02-6   389
3     BRD-A00938334-001-01-3   369
4     BRD-A01636364-003-15-1   245
...                      ...   ...
1139  BRD-K99545815-001-06-3   215
1140  BRD-K99604664-001-01-1   290
1141  BRD-K99749624-001-07-0   133
1142  BRD-K99792991-001-34-9   145
1143                    DMSO  3912

[1144 rows x 2 columns]
8951/8974 [============================>.] - ETA: 5s - batch: 4475.0000 - size: 64.0000 - loss: 0.8179 - acc: 0.8946 - top_5: 0.9860 >> Shuffling training sample with 574288 examples
8974/8974 [==============================] - 2355s 262ms/step - batch: 4486.5000 - size: 64.0000 - loss: 0.8179 - acc: 0.8947 - top_5: 0.9860 - val_loss: 1.9099 - val_acc: 0.6316 - val_top_5: 0.8734 - lr: 1.0956e-04
Complete! Closing session. deepprofiler/__main__.py:168: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.
  dset = deepprofiler.dataset.image_dataset.read_dataset(context.obj["config"], mode='train')
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  "The `lr` argument is deprecated, use `learning_rate` instead.")
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:1246: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`model.fit_generator` is deprecated and '
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
All set.
-------------
finished training 14383844
