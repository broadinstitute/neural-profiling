Matplotlib created a temporary config/cache directory at /var/lib/condor/execute/slot1/dir_38695/matplotlib-ydk8j1ui because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
2021-08-26 00:45:15.604641: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-08-26 00:45:16,564 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Reading metadata form /local_group_storage/broad_data/michael/training/inputs/metadata/823_index.csv
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 52037 entries, 0 to 52036
Data columns (total 21 columns):
 #   Column                     Non-Null Count  Dtype  
---  ------                     --------------  -----  
 0   Metadata_Plate             52037 non-null  object 
 1   Metadata_Well              52037 non-null  object 
 2   Metadata_Site              52037 non-null  int64  
 3   Metadata_broad_sample      52037 non-null  object 
 4   Metadata_moa               52037 non-null  object 
 5   Metadata_mmoles_per_liter  52037 non-null  float64
 6   Metadata_dose_recode       52037 non-null  int64  
 7   RNA                        52037 non-null  object 
 8   ER                         52037 non-null  object 
 9   AGP                        52037 non-null  object 
 10  Mito                       52037 non-null  object 
 11  DNA                        52037 non-null  object 
 12  Concentration              52037 non-null  object 
 13  Treatment_ID               52037 non-null  int64  
 14  Compound                   52037 non-null  object 
 15  pert_iname                 52037 non-null  object 
 16  Treatment_Replicate        52037 non-null  int64  
 17  Treatment                  52037 non-null  object 
 18  Plate_Map_Name             52037 non-null  object 
 19  Split                      52037 non-null  object 
 20  Metadata_Batch_Number      52037 non-null  int64  
dtypes: float64(1), int64(5), object(15)
memory usage: 8.3+ MB
None
{'BRD-A02710418-003-11-8': 0, 'BRD-A05186015-003-19-8': 1, 'BRD-A05457250-001-05-0': 2, 'BRD-A05523972-001-01-5': 3, 'BRD-A06935312-001-04-3': 4, 'BRD-A07986123-001-02-8': 5, 'BRD-A10012892-001-01-9': 6, 'BRD-A12230535-001-06-7': 7, 'BRD-A12237696-001-04-2': 8, 'BRD-A12994259-001-02-1': 9, 'BRD-A13084692-001-17-3': 10, 'BRD-A14262390-065-01-8': 11, 'BRD-A14886633-001-01-6': 12, 'BRD-A15202882-003-02-7': 13, 'BRD-A15435692-003-02-3': 14, 'BRD-A15909516-001-06-6': 15, 'BRD-A16997652-001-02-3': 16, 'BRD-A18611368-001-01-5': 17, 'BRD-A19195498-050-14-1': 18, 'BRD-A19633847-050-32-1': 19, 'BRD-A20348246-001-15-8': 20, 'BRD-A21858158-001-23-5': 21, 'BRD-A22081593-001-11-1': 22, 'BRD-A22380646-236-05-8': 23, 'BRD-A22642447-001-01-9': 24, 'BRD-A23067620-300-01-3': 25, 'BRD-A24514565-001-09-7': 26, 'BRD-A24560335-300-01-2': 27, 'BRD-A25619068-003-03-4': 28, 'BRD-A26032986-050-02-1': 29, 'BRD-A26384407-001-25-1': 30, 'BRD-A26503646-001-16-6': 31, 'BRD-A27732521-003-08-3': 32, 'BRD-A28545468-003-16-6': 33, 'BRD-A28787076-001-04-8': 34, 'BRD-A29289453-001-04-7': 35, 'BRD-A29322418-237-04-0': 36, 'BRD-A29520968-001-02-7': 37, 'BRD-A29623586-001-01-3': 38, 'BRD-A29854054-236-12-6': 39, 'BRD-A30051119-002-01-8': 40, 'BRD-A30984645-001-01-5': 41, 'BRD-A31095847-001-02-3': 42, 'BRD-A31159102-003-30-4': 43, 'BRD-A31811760-001-06-7': 44, 'BRD-A33447119-001-10-8': 45, 'BRD-A33692381-001-01-9': 46, 'BRD-A36331462-001-02-1': 47, 'BRD-A38218502-001-01-2': 48, 'BRD-A38592941-001-02-7': 49, 'BRD-A42699921-001-02-8': 50, 'BRD-A44863528-001-13-2': 51, 'BRD-A45153512-001-01-0': 52, 'BRD-A47364545-003-02-6': 53, 'BRD-A47598013-004-16-0': 54, 'BRD-A48430263-003-17-2': 55, 'BRD-A48570745-001-02-9': 56, 'BRD-A49160188-003-12-7': 57, 'BRD-A49838158-001-01-1': 58, 'BRD-A50033377-001-02-8': 59, 'BRD-A51078674-003-01-0': 60, 'BRD-A51964809-003-12-6': 61, 'BRD-A52252998-001-01-3': 62, 'BRD-A52660433-066-02-1': 63, 'BRD-A52922642-001-03-7': 64, 'BRD-A53566267-001-01-9': 65, 'BRD-A54880345-001-20-9': 66, 'BRD-A55962179-001-22-1': 67, 'BRD-A56085258-001-01-8': 68, 'BRD-A56371469-001-03-3': 69, 'BRD-A61793559-001-15-6': 70, 'BRD-A62879835-001-04-2': 71, 'BRD-A63236097-001-01-3': 72, 'BRD-A63675168-001-01-6': 73, 'BRD-A65051990-001-12-9': 74, 'BRD-A68304895-003-02-2': 75, 'BRD-A68942014-003-01-7': 76, 'BRD-A69815203-001-07-6': 77, 'BRD-A70858459-001-01-7': 78, 'BRD-A70998768-004-01-1': 79, 'BRD-A73741725-001-02-8': 80, 'BRD-A74914197-001-02-9': 81, 'BRD-A78341343-001-01-6': 82, 'BRD-A80017228-001-25-7': 83, 'BRD-A82035391-001-02-7': 84, 'BRD-A82156122-001-01-9': 85, 'BRD-A82395837-001-01-9': 86, 'BRD-A83081521-001-02-3': 87, 'BRD-A86871940-001-01-9': 88, 'BRD-A87130939-001-07-9': 89, 'BRD-A87983072-001-01-1': 90, 'BRD-A89164055-001-03-3': 91, 'BRD-A90547603-001-02-5': 92, 'BRD-A91699651-316-10-9': 93, 'BRD-A92630576-050-24-1': 94, 'BRD-A93000692-001-08-1': 95, 'BRD-A93255169-001-28-3': 96, 'BRD-A94756469-001-04-7': 97, 'BRD-A95032015-065-01-2': 98, 'BRD-A96456596-001-02-2': 99, 'BRD-A96754982-001-01-4': 100, 'BRD-A97437073-050-14-5': 101, 'BRD-A97808748-001-03-8': 102, 'BRD-A98845662-036-03-7': 103, 'BRD-K04691817-001-01-8': 104, 'BRD-K05236810-001-19-0': 105, 'BRD-K05804044-001-06-0': 106, 'BRD-K06240250-001-01-6': 107, 'BRD-K06557128-001-07-0': 108, 'BRD-K06858286-001-01-3': 109, 'BRD-K06878038-001-18-6': 110, 'BRD-K07106112-003-03-8': 111, 'BRD-K07208025-001-29-7': 112, 'BRD-K07237224-001-19-6': 113, 'BRD-K07609981-001-01-7': 114, 'BRD-K07857022-002-01-1': 115, 'BRD-K07954936-001-01-3': 116, 'BRD-K08248804-001-01-8': 117, 'BRD-K08586861-001-01-1': 118, 'BRD-K08703257-001-12-1': 119, 'BRD-K08976401-001-18-5': 120, 'BRD-K09090949-001-01-9': 121, 'BRD-K09132007-001-07-5': 122, 'BRD-K09255212-001-16-6': 123, 'BRD-K09372874-001-01-0': 124, 'BRD-K09549677-300-03-4': 125, 'BRD-K09602097-001-13-6': 126, 'BRD-K09951645-001-06-8': 127, 'BRD-K10843433-001-22-7': 128, 'BRD-K10859802-001-01-0': 129, 'BRD-K10961822-001-05-1': 130, 'BRD-K11073688-001-01-6': 131, 'BRD-K11153516-001-05-5': 132, 'BRD-K11267252-001-04-4': 133, 'BRD-K12219985-001-26-1': 134, 'BRD-K12609457-001-03-1': 135, 'BRD-K12737986-001-01-4': 136, 'BRD-K12885236-001-02-7': 137, 'BRD-K13296708-001-05-8': 138, 'BRD-K13356952-001-25-1': 139, 'BRD-K13756951-001-01-4': 140, 'BRD-K15108141-001-06-6': 141, 'BRD-K15179879-001-03-2': 142, 'BRD-K15318383-201-01-5': 143, 'BRD-K15409150-001-05-8': 144, 'BRD-K15502390-001-20-9': 145, 'BRD-K15507868-001-03-7': 146, 'BRD-K15976406-001-03-3': 147, 'BRD-K16295392-003-01-3': 148, 'BRD-K16761703-001-03-8': 149, 'BRD-K16762525-001-01-6': 150, 'BRD-K17075857-001-17-6': 151, 'BRD-K17513304-001-01-9': 152, 'BRD-K17705806-003-04-4': 153, 'BRD-K17849083-001-31-1': 154, 'BRD-K17930269-001-01-8': 155, 'BRD-K17953908-001-01-7': 156, 'BRD-K18157228-001-01-7': 157, 'BRD-K18779551-003-07-8': 158, 'BRD-K18922609-004-23-1': 159, 'BRD-K19061412-001-02-4': 160, 'BRD-K19111024-001-20-9': 161, 'BRD-K19284129-001-02-6': 162, 'BRD-K19388745-003-01-7': 163, 'BRD-K19416115-001-05-3': 164, 'BRD-K19477839-001-07-6': 165, 'BRD-K19761926-001-02-8': 166, 'BRD-K20008181-001-01-3': 167, 'BRD-K20079257-001-09-6': 168, 'BRD-K20722021-001-02-1': 169, 'BRD-K20738689-001-01-2': 170, 'BRD-K20897876-001-10-0': 171, 'BRD-K20920669-304-09-1': 172, 'BRD-K20958582-001-01-4': 173, 'BRD-K21396683-001-04-8': 174, 'BRD-K21450440-001-14-6': 175, 'BRD-K21908111-001-01-8': 176, 'BRD-K22031190-001-23-6': 177, 'BRD-K22097830-001-01-9': 178, 'BRD-K22662435-001-18-3': 179, 'BRD-K22822991-001-02-3': 180, 'BRD-K22848513-001-01-9': 181, 'BRD-K22936972-003-23-6': 182, 'BRD-K22969690-001-04-2': 183, 'BRD-K23190681-001-01-1': 184, 'BRD-K23672206-001-01-4': 185, 'BRD-K23976833-001-01-0': 186, 'BRD-K24771047-001-01-6': 187, 'BRD-K24844714-001-24-5': 188, 'BRD-K24968862-001-01-0': 189, 'BRD-K25114078-003-08-1': 190, 'BRD-K25140590-001-03-0': 191, 'BRD-K25361343-001-01-6': 192, 'BRD-K25433859-003-25-4': 193, 'BRD-K26325692-003-01-3': 194, 'BRD-K26341917-001-01-3': 195, 'BRD-K26619122-001-02-1': 196, 'BRD-K26823213-001-02-9': 197, 'BRD-K27182532-001-02-3': 198, 'BRD-K27204852-001-01-9': 199, 'BRD-K27938825-001-02-4': 200, 'BRD-K27955832-001-02-9': 201, 'BRD-K28115081-001-02-7': 202, 'BRD-K28183345-003-11-4': 203, 'BRD-K28217197-001-01-4': 204, 'BRD-K28428262-001-04-1': 205, 'BRD-K28542495-003-13-5': 206, 'BRD-K28667793-001-28-1': 207, 'BRD-K28912512-001-23-2': 208, 'BRD-K28984613-001-01-5': 209, 'BRD-K29133151-001-03-2': 210, 'BRD-K29322660-001-01-9': 211, 'BRD-K29530284-001-06-2': 212, 'BRD-K29673530-001-05-4': 213, 'BRD-K29735307-001-02-9': 214, 'BRD-K29950728-048-17-4': 215, 'BRD-K30020243-051-02-5': 216, 'BRD-K30550578-001-01-3': 217, 'BRD-K31111078-001-04-2': 218, 'BRD-K31135544-001-07-0': 219, 'BRD-K31309378-001-01-5': 220, 'BRD-K31342827-001-08-8': 221, 'BRD-K31476763-001-01-5': 222, 'BRD-K31495718-001-01-1': 223, 'BRD-K31841515-001-07-8': 224, 'BRD-K32101625-001-01-6': 225, 'BRD-K32107296-001-16-9': 226, 'BRD-K32164935-001-30-8': 227, 'BRD-K32218650-001-01-6': 228, 'BRD-K32247306-001-29-4': 229, 'BRD-K32285926-001-02-1': 230, 'BRD-K32318651-001-23-7': 231, 'BRD-K32405725-001-02-8': 232, 'BRD-K32501161-300-06-2': 233, 'BRD-K33106058-001-16-8': 234, 'BRD-K33141550-003-05-7': 235, 'BRD-K33379087-001-07-5': 236, 'BRD-K33732501-004-01-0': 237, 'BRD-K33882852-003-02-8': 238, 'BRD-K34022604-001-06-6': 239, 'BRD-K34154330-003-06-4': 240, 'BRD-K34185671-001-02-8': 241, 'BRD-K34776109-001-16-6': 242, 'BRD-K35169477-001-01-9': 243, 'BRD-K35189033-001-26-1': 244, 'BRD-K35520305-001-17-7': 245, 'BRD-K35589454-003-01-1': 246, 'BRD-K35629949-001-02-0': 247, 'BRD-K35775715-001-03-1': 248, 'BRD-K36269323-300-02-6': 249, 'BRD-K36270037-001-01-7': 250, 'BRD-K36386086-001-01-1': 251, 'BRD-K36467523-001-02-8': 252, 'BRD-K36862742-001-25-6': 253, 'BRD-K37111771-300-02-6': 254, 'BRD-K39503511-001-03-9': 255, 'BRD-K40797222-001-01-8': 256, 'BRD-K40870905-001-01-7': 257, 'BRD-K41599323-001-02-3': 258, 'BRD-K43723251-001-01-5': 259, 'BRD-K43797669-001-30-4': 260, 'BRD-K44366189-001-01-9': 261, 'BRD-K44408410-001-17-6': 262, 'BRD-K44771174-066-01-0': 263, 'BRD-K44974079-001-01-3': 264, 'BRD-K45033733-001-12-2': 265, 'BRD-K45071273-003-25-6': 266, 'BRD-K45117373-001-02-9': 267, 'BRD-K45245728-335-01-4': 268, 'BRD-K45252063-001-13-6': 269, 'BRD-K45275534-001-01-3': 270, 'BRD-K45542189-048-22-1': 271, 'BRD-K45746021-003-01-9': 272, 'BRD-K46018455-001-27-6': 273, 'BRD-K46133855-304-03-8': 274, 'BRD-K46290096-001-01-1': 275, 'BRD-K46424862-001-14-1': 276, 'BRD-K46604138-001-01-3': 277, 'BRD-K47095176-001-01-6': 278, 'BRD-K47539947-001-03-7': 279, 'BRD-K47554101-001-01-2': 280, 'BRD-K47780086-001-07-9': 281, 'BRD-K48068743-001-01-6': 282, 'BRD-K48213016-001-01-8': 283, 'BRD-K48367671-001-05-9': 284, 'BRD-K48812570-001-02-3': 285, 'BRD-K48892307-001-04-1': 286, 'BRD-K48894757-001-01-8': 287, 'BRD-K49075727-001-08-5': 288, 'BRD-K49350383-001-13-7': 289, 'BRD-K49555808-001-03-9': 290, 'BRD-K49840922-001-05-1': 291, 'BRD-K50133271-001-18-7': 292, 'BRD-K50398167-236-22-7': 293, 'BRD-K50859149-001-19-5': 294, 'BRD-K51040301-001-02-1': 295, 'BRD-K51263939-001-08-6': 296, 'BRD-K51333959-003-01-3': 297, 'BRD-K51350053-048-16-5': 298, 'BRD-K51662849-001-05-4': 299, 'BRD-K51747290-001-13-1': 300, 'BRD-K52172416-001-11-4': 301, 'BRD-K52183142-001-01-3': 302, 'BRD-K52618540-001-09-9': 303, 'BRD-K52662033-003-21-2': 304, 'BRD-K52959329-238-01-9': 305, 'BRD-K52989797-003-26-4': 306, 'BRD-K53061490-003-13-9': 307, 'BRD-K53414658-001-08-2': 308, 'BRD-K53517854-051-01-4': 309, 'BRD-K53765467-001-02-1': 310, 'BRD-K53814070-310-01-3': 311, 'BRD-K53963539-004-02-0': 312, 'BRD-K53979406-003-02-8': 313, 'BRD-K54416256-001-19-9': 314, 'BRD-K54472332-001-03-4': 315, 'BRD-K54936858-001-01-6': 316, 'BRD-K55026842-001-01-4': 317, 'BRD-K55512740-001-01-6': 318, 'BRD-K55748775-001-02-2': 319, 'BRD-K55781385-001-01-7': 320, 'BRD-K55847762-304-01-7': 321, 'BRD-K55966568-001-05-4': 322, 'BRD-K56032964-001-02-1': 323, 'BRD-K56301217-001-07-4': 324, 'BRD-K56343971-001-10-6': 325, 'BRD-K56405753-001-02-4': 326, 'BRD-K56751279-300-01-4': 327, 'BRD-K56810756-001-03-0': 328, 'BRD-K57041787-001-02-6': 329, 'BRD-K57252450-001-02-5': 330, 'BRD-K58010567-003-02-2': 331, 'BRD-K58114536-001-01-6': 332, 'BRD-K58211978-001-01-5': 333, 'BRD-K58501140-002-01-0': 334, 'BRD-K58736316-001-09-5': 335, 'BRD-K59013864-001-01-1': 336, 'BRD-K59037100-001-14-7': 337, 'BRD-K59325863-001-02-8': 338, 'BRD-K59331299-001-01-2': 339, 'BRD-K59433843-001-01-7': 340, 'BRD-K59436580-001-01-7': 341, 'BRD-K59506194-015-04-9': 342, 'BRD-K59574735-001-11-8': 343, 'BRD-K60341624-001-02-2': 344, 'BRD-K61036791-001-01-6': 345, 'BRD-K61250553-003-32-2': 346, 'BRD-K61452026-001-04-6': 347, 'BRD-K61693562-300-01-7': 348, 'BRD-K62196610-001-01-6': 349, 'BRD-K62363391-001-24-9': 350, 'BRD-K62391742-001-03-0': 351, 'BRD-K62965247-001-04-9': 352, 'BRD-K63550407-001-12-7': 353, 'BRD-K63630713-001-25-8': 354, 'BRD-K63750851-001-20-7': 355, 'BRD-K63861289-001-19-6': 356, 'BRD-K65991129-001-02-9': 357, 'BRD-K66035042-001-10-1': 358, 'BRD-K67789209-001-01-0': 359, 'BRD-K67901620-001-02-0': 360, 'BRD-K68095457-001-10-1': 361, 'BRD-K68132782-003-13-8': 362, 'BRD-K68232413-001-01-2': 363, 'BRD-K68392338-003-02-0': 364, 'BRD-K68552125-001-05-3': 365, 'BRD-K68870568-066-01-5': 366, 'BRD-K68938568-001-01-7': 367, 'BRD-K69001009-001-02-8': 368, 'BRD-K69236721-001-02-7': 369, 'BRD-K69776681-001-03-8': 370, 'BRD-K70301465-001-02-6': 371, 'BRD-K70301876-034-13-7': 372, 'BRD-K70358946-001-15-7': 373, 'BRD-K70463136-001-01-5': 374, 'BRD-K70464547-003-01-2': 375, 'BRD-K70490179-300-01-2': 376, 'BRD-K70507123-001-09-7': 377, 'BRD-K70511574-001-06-9': 378, 'BRD-K70557564-305-03-6': 379, 'BRD-K71075609-003-01-0': 380, 'BRD-K71106091-001-06-1': 381, 'BRD-K71164191-001-01-0': 382, 'BRD-K71221037-001-01-6': 383, 'BRD-K71289571-001-11-4': 384, 'BRD-K71822263-001-03-2': 385, 'BRD-K72005722-001-01-2': 386, 'BRD-K72093121-001-16-3': 387, 'BRD-K72215350-001-06-5': 388, 'BRD-K72827473-001-01-0': 389, 'BRD-K72922393-003-15-2': 390, 'BRD-K73109821-001-20-1': 391, 'BRD-K73319509-001-08-0': 392, 'BRD-K73691377-001-01-6': 393, 'BRD-K73794685-001-01-5': 394, 'BRD-K74141488-003-11-2': 395, 'BRD-K74371986-001-01-7': 396, 'BRD-K74514084-001-03-9': 397, 'BRD-K74717603-001-02-2': 398, 'BRD-K74763371-002-04-0': 399, 'BRD-K75649340-001-13-1': 400, 'BRD-K75911534-001-01-6': 401, 'BRD-K76197012-001-01-2': 402, 'BRD-K76617868-003-11-9': 403, 'BRD-K76674262-001-03-3': 404, 'BRD-K76908866-001-07-6': 405, 'BRD-K77396579-300-01-0': 406, 'BRD-K77561571-001-01-1': 407, 'BRD-K77685957-300-09-1': 408, 'BRD-K77695569-001-30-0': 409, 'BRD-K78010432-001-21-5': 410, 'BRD-K78118466-001-03-3': 411, 'BRD-K78303961-001-02-3': 412, 'BRD-K78431006-001-10-2': 413, 'BRD-K78659596-001-03-9': 414, 'BRD-K79254416-001-22-6': 415, 'BRD-K79404599-001-09-3': 416, 'BRD-K79501723-001-04-6': 417, 'BRD-K79602928-003-19-9': 418, 'BRD-K80082640-001-01-0': 419, 'BRD-K80396088-001-12-0': 420, 'BRD-K80535353-001-01-4': 421, 'BRD-K80700417-001-04-2': 422, 'BRD-K81473089-003-26-1': 423, 'BRD-K81694556-003-01-9': 424, 'BRD-K81916719-001-13-9': 425, 'BRD-K82164249-001-03-5': 426, 'BRD-K82225283-001-03-1': 427, 'BRD-K82522873-001-01-1': 428, 'BRD-K82603084-408-01-1': 429, 'BRD-K82746043-001-15-1': 430, 'BRD-K82767007-001-01-1': 431, 'BRD-K82846253-001-15-4': 432, 'BRD-K83057217-001-01-2': 433, 'BRD-K83508485-001-02-7': 434, 'BRD-K83699324-001-01-1': 435, 'BRD-K84564571-001-02-4': 436, 'BRD-K84783599-001-01-0': 437, 'BRD-K84794093-001-07-5': 438, 'BRD-K84798689-236-02-9': 439, 'BRD-K84996356-001-01-1': 440, 'BRD-K85119730-001-28-9': 441, 'BRD-K85140930-001-12-7': 442, 'BRD-K85679373-001-01-1': 443, 'BRD-K85833139-001-01-9': 444, 'BRD-K85925969-001-17-4': 445, 'BRD-K86307448-001-17-5': 446, 'BRD-K86892782-001-17-0': 447, 'BRD-K87156652-001-12-7': 448, 'BRD-K87300616-001-01-9': 449, 'BRD-K87782578-001-01-4': 450, 'BRD-K88429204-001-35-1': 451, 'BRD-K88506063-001-01-8': 452, 'BRD-K88544581-001-06-1': 453, 'BRD-K88611939-001-22-4': 454, 'BRD-K88789588-001-14-9': 455, 'BRD-K88807631-001-01-3': 456, 'BRD-K89104321-003-14-8': 457, 'BRD-K89274813-001-02-3': 458, 'BRD-K89402695-001-02-3': 459, 'BRD-K90777969-300-01-2': 460, 'BRD-K90868879-001-03-8': 461, 'BRD-K90948141-001-01-4': 462, 'BRD-K91159026-001-01-7': 463, 'BRD-K91263825-003-21-4': 464, 'BRD-K91290917-300-01-8': 465, 'BRD-K91456750-238-01-7': 466, 'BRD-K91495480-001-02-2': 467, 'BRD-K91544578-001-03-8': 468, 'BRD-K91822704-003-07-2': 469, 'BRD-K92041145-001-09-5': 470, 'BRD-K92428153-001-04-4': 471, 'BRD-K92428232-001-10-6': 472, 'BRD-K93754473-048-20-2': 473, 'BRD-K93779381-001-01-9': 474, 'BRD-K93869735-001-01-1': 475, 'BRD-K94534639-001-02-5': 476, 'BRD-K95142244-001-01-5': 477, 'BRD-K95412502-003-01-5': 478, 'BRD-K95739795-001-03-7': 479, 'BRD-K95921201-001-14-6': 480, 'BRD-K96123349-236-02-8': 481, 'BRD-K96194081-001-10-2': 482, 'BRD-K96342952-001-01-2': 483, 'BRD-K96550715-001-02-6': 484, 'BRD-K96615647-001-01-2': 485, 'BRD-K96671969-001-03-1': 486, 'BRD-K96720755-001-02-6': 487, 'BRD-K96862998-001-15-5': 488, 'BRD-K97010173-001-04-1': 489, 'BRD-K97045029-001-02-7': 490, 'BRD-K97101532-001-02-8': 491, 'BRD-K97428065-001-01-2': 492, 'BRD-K97472745-001-01-8': 493, 'BRD-K97729603-001-01-2': 494, 'BRD-K97746869-001-27-0': 495, 'BRD-K97799481-001-16-0': 496, 'BRD-K97884852-001-05-4': 497, 'BRD-K97963946-001-01-3': 498, 'BRD-K98769987-001-23-7': 499, 'BRD-K99092662-001-01-1': 500, 'BRD-K99383816-001-02-7': 501, 'BRD-K99504665-001-01-2': 502, 'BRD-K99545815-001-06-3': 503, 'BRD-K99749624-001-07-0': 504, 'BRD-K99792991-001-34-9': 505, 'DMSO': 506}
Reading single-cell locations
deepprofiler/__main__.py:162: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.
  dset = deepprofiler.dataset.image_dataset.read_dataset(context.obj["config"], mode='train')
2021-08-26 00:46:25,113 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
2021-08-26 00:46:27,198 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-08-26 00:46:27,198 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-08-26 00:46:27,200 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
2021-08-26 00:46:27,427 - WARNING - From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
Model: "model"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 128, 128, 5) 0                                            
__________________________________________________________________________________________________
augmentation_layer (Augmentatio (None, 128, 128, 5)  0           input_1[0][0]                    
__________________________________________________________________________________________________
rescaling (Rescaling)           (None, 128, 128, 5)  0           augmentation_layer[0][0]         
__________________________________________________________________________________________________
normalization (Normalization)   (None, 128, 128, 5)  11          rescaling[0][0]                  
__________________________________________________________________________________________________
stem_conv_pad (ZeroPadding2D)   (None, 129, 129, 5)  0           normalization[0][0]              
__________________________________________________________________________________________________
stem_conv (Conv2D)              (None, 64, 64, 32)   1440        stem_conv_pad[0][0]              
__________________________________________________________________________________________________
stem_bn (BatchNormalization)    (None, 64, 64, 32)   128         stem_conv[0][0]                  
__________________________________________________________________________________________________
stem_activation (Activation)    (None, 64, 64, 32)   0           stem_bn[0][0]                    
__________________________________________________________________________________________________
block1a_dwconv (DepthwiseConv2D (None, 64, 64, 32)   288         stem_activation[0][0]            
__________________________________________________________________________________________________
block1a_bn (BatchNormalization) (None, 64, 64, 32)   128         block1a_dwconv[0][0]             
__________________________________________________________________________________________________
block1a_activation (Activation) (None, 64, 64, 32)   0           block1a_bn[0][0]                 
__________________________________________________________________________________________________
block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         
__________________________________________________________________________________________________
block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         
__________________________________________________________________________________________________
block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          
__________________________________________________________________________________________________
block1a_se_excite (Multiply)    (None, 64, 64, 32)   0           block1a_activation[0][0]         
                                                                 block1a_se_expand[0][0]          
__________________________________________________________________________________________________
block1a_project_conv (Conv2D)   (None, 64, 64, 16)   512         block1a_se_excite[0][0]          
__________________________________________________________________________________________________
block1a_project_bn (BatchNormal (None, 64, 64, 16)   64          block1a_project_conv[0][0]       
__________________________________________________________________________________________________
block2a_expand_conv (Conv2D)    (None, 64, 64, 96)   1536        block1a_project_bn[0][0]         
__________________________________________________________________________________________________
block2a_expand_bn (BatchNormali (None, 64, 64, 96)   384         block2a_expand_conv[0][0]        
__________________________________________________________________________________________________
block2a_expand_activation (Acti (None, 64, 64, 96)   0           block2a_expand_bn[0][0]          
__________________________________________________________________________________________________
block2a_dwconv_pad (ZeroPadding (None, 65, 65, 96)   0           block2a_expand_activation[0][0]  
__________________________________________________________________________________________________
block2a_dwconv (DepthwiseConv2D (None, 32, 32, 96)   864         block2a_dwconv_pad[0][0]         
__________________________________________________________________________________________________
block2a_bn (BatchNormalization) (None, 32, 32, 96)   384         block2a_dwconv[0][0]             
__________________________________________________________________________________________________
block2a_activation (Activation) (None, 32, 32, 96)   0           block2a_bn[0][0]                 
__________________________________________________________________________________________________
block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         
__________________________________________________________________________________________________
block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         
__________________________________________________________________________________________________
block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          
__________________________________________________________________________________________________
block2a_se_excite (Multiply)    (None, 32, 32, 96)   0           block2a_activation[0][0]         
                                                                 block2a_se_expand[0][0]          
__________________________________________________________________________________________________
block2a_project_conv (Conv2D)   (None, 32, 32, 24)   2304        block2a_se_excite[0][0]          
__________________________________________________________________________________________________
block2a_project_bn (BatchNormal (None, 32, 32, 24)   96          block2a_project_conv[0][0]       
__________________________________________________________________________________________________
block2b_expand_conv (Conv2D)    (None, 32, 32, 144)  3456        block2a_project_bn[0][0]         
__________________________________________________________________________________________________
block2b_expand_bn (BatchNormali (None, 32, 32, 144)  576         block2b_expand_conv[0][0]        
__________________________________________________________________________________________________
block2b_expand_activation (Acti (None, 32, 32, 144)  0           block2b_expand_bn[0][0]          
__________________________________________________________________________________________________
block2b_dwconv (DepthwiseConv2D (None, 32, 32, 144)  1296        block2b_expand_activation[0][0]  
__________________________________________________________________________________________________
block2b_bn (BatchNormalization) (None, 32, 32, 144)  576         block2b_dwconv[0][0]             
__________________________________________________________________________________________________
block2b_activation (Activation) (None, 32, 32, 144)  0           block2b_bn[0][0]                 
__________________________________________________________________________________________________
block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         
__________________________________________________________________________________________________
block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         
__________________________________________________________________________________________________
block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          
__________________________________________________________________________________________________
block2b_se_excite (Multiply)    (None, 32, 32, 144)  0           block2b_activation[0][0]         
                                                                 block2b_se_expand[0][0]          
__________________________________________________________________________________________________
block2b_project_conv (Conv2D)   (None, 32, 32, 24)   3456        block2b_se_excite[0][0]          
__________________________________________________________________________________________________
block2b_project_bn (BatchNormal (None, 32, 32, 24)   96          block2b_project_conv[0][0]       
__________________________________________________________________________________________________
block2b_drop (Dropout)          (None, 32, 32, 24)   0           block2b_project_bn[0][0]         
__________________________________________________________________________________________________
block2b_add (Add)               (None, 32, 32, 24)   0           block2b_drop[0][0]               
                                                                 block2a_project_bn[0][0]         
__________________________________________________________________________________________________
block3a_expand_conv (Conv2D)    (None, 32, 32, 144)  3456        block2b_add[0][0]                
__________________________________________________________________________________________________
block3a_expand_bn (BatchNormali (None, 32, 32, 144)  576         block3a_expand_conv[0][0]        
__________________________________________________________________________________________________
block3a_expand_activation (Acti (None, 32, 32, 144)  0           block3a_expand_bn[0][0]          
__________________________________________________________________________________________________
block3a_dwconv_pad (ZeroPadding (None, 35, 35, 144)  0           block3a_expand_activation[0][0]  
__________________________________________________________________________________________________
block3a_dwconv (DepthwiseConv2D (None, 16, 16, 144)  3600        block3a_dwconv_pad[0][0]         
__________________________________________________________________________________________________
block3a_bn (BatchNormalization) (None, 16, 16, 144)  576         block3a_dwconv[0][0]             
__________________________________________________________________________________________________
block3a_activation (Activation) (None, 16, 16, 144)  0           block3a_bn[0][0]                 
__________________________________________________________________________________________________
block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         
__________________________________________________________________________________________________
block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         
__________________________________________________________________________________________________
block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          
__________________________________________________________________________________________________
block3a_se_excite (Multiply)    (None, 16, 16, 144)  0           block3a_activation[0][0]         
                                                                 block3a_se_expand[0][0]          
__________________________________________________________________________________________________
block3a_project_conv (Conv2D)   (None, 16, 16, 40)   5760        block3a_se_excite[0][0]          
__________________________________________________________________________________________________
block3a_project_bn (BatchNormal (None, 16, 16, 40)   160         block3a_project_conv[0][0]       
__________________________________________________________________________________________________
block3b_expand_conv (Conv2D)    (None, 16, 16, 240)  9600        block3a_project_bn[0][0]         
__________________________________________________________________________________________________
block3b_expand_bn (BatchNormali (None, 16, 16, 240)  960         block3b_expand_conv[0][0]        
__________________________________________________________________________________________________
block3b_expand_activation (Acti (None, 16, 16, 240)  0           block3b_expand_bn[0][0]          
__________________________________________________________________________________________________
block3b_dwconv (DepthwiseConv2D (None, 16, 16, 240)  6000        block3b_expand_activation[0][0]  
__________________________________________________________________________________________________
block3b_bn (BatchNormalization) (None, 16, 16, 240)  960         block3b_dwconv[0][0]             
__________________________________________________________________________________________________
block3b_activation (Activation) (None, 16, 16, 240)  0           block3b_bn[0][0]                 
__________________________________________________________________________________________________
block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         
__________________________________________________________________________________________________
block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         
__________________________________________________________________________________________________
block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          
__________________________________________________________________________________________________
block3b_se_excite (Multiply)    (None, 16, 16, 240)  0           block3b_activation[0][0]         
                                                                 block3b_se_expand[0][0]          
__________________________________________________________________________________________________
block3b_project_conv (Conv2D)   (None, 16, 16, 40)   9600        block3b_se_excite[0][0]          
__________________________________________________________________________________________________
block3b_project_bn (BatchNormal (None, 16, 16, 40)   160         block3b_project_conv[0][0]       
__________________________________________________________________________________________________
block3b_drop (Dropout)          (None, 16, 16, 40)   0           block3b_project_bn[0][0]         
__________________________________________________________________________________________________
block3b_add (Add)               (None, 16, 16, 40)   0           block3b_drop[0][0]               
                                                                 block3a_project_bn[0][0]         
__________________________________________________________________________________________________
block4a_expand_conv (Conv2D)    (None, 16, 16, 240)  9600        block3b_add[0][0]                
__________________________________________________________________________________________________
block4a_expand_bn (BatchNormali (None, 16, 16, 240)  960         block4a_expand_conv[0][0]        
__________________________________________________________________________________________________
block4a_expand_activation (Acti (None, 16, 16, 240)  0           block4a_expand_bn[0][0]          
__________________________________________________________________________________________________
block4a_dwconv_pad (ZeroPadding (None, 17, 17, 240)  0           block4a_expand_activation[0][0]  
__________________________________________________________________________________________________
block4a_dwconv (DepthwiseConv2D (None, 8, 8, 240)    2160        block4a_dwconv_pad[0][0]         
__________________________________________________________________________________________________
block4a_bn (BatchNormalization) (None, 8, 8, 240)    960         block4a_dwconv[0][0]             
__________________________________________________________________________________________________
block4a_activation (Activation) (None, 8, 8, 240)    0           block4a_bn[0][0]                 
__________________________________________________________________________________________________
block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         
__________________________________________________________________________________________________
block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         
__________________________________________________________________________________________________
block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          
__________________________________________________________________________________________________
block4a_se_excite (Multiply)    (None, 8, 8, 240)    0           block4a_activation[0][0]         
                                                                 block4a_se_expand[0][0]          
__________________________________________________________________________________________________
block4a_project_conv (Conv2D)   (None, 8, 8, 80)     19200       block4a_se_excite[0][0]          
__________________________________________________________________________________________________
block4a_project_bn (BatchNormal (None, 8, 8, 80)     320         block4a_project_conv[0][0]       
__________________________________________________________________________________________________
block4b_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4a_project_bn[0][0]         
__________________________________________________________________________________________________
block4b_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4b_expand_conv[0][0]        
__________________________________________________________________________________________________
block4b_expand_activation (Acti (None, 8, 8, 480)    0           block4b_expand_bn[0][0]          
__________________________________________________________________________________________________
block4b_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4b_expand_activation[0][0]  
__________________________________________________________________________________________________
block4b_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4b_dwconv[0][0]             
__________________________________________________________________________________________________
block4b_activation (Activation) (None, 8, 8, 480)    0           block4b_bn[0][0]                 
__________________________________________________________________________________________________
block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         
__________________________________________________________________________________________________
block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         
__________________________________________________________________________________________________
block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          
__________________________________________________________________________________________________
block4b_se_excite (Multiply)    (None, 8, 8, 480)    0           block4b_activation[0][0]         
                                                                 block4b_se_expand[0][0]          
__________________________________________________________________________________________________
block4b_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4b_se_excite[0][0]          
__________________________________________________________________________________________________
block4b_project_bn (BatchNormal (None, 8, 8, 80)     320         block4b_project_conv[0][0]       
__________________________________________________________________________________________________
block4b_drop (Dropout)          (None, 8, 8, 80)     0           block4b_project_bn[0][0]         
__________________________________________________________________________________________________
block4b_add (Add)               (None, 8, 8, 80)     0           block4b_drop[0][0]               
                                                                 block4a_project_bn[0][0]         
__________________________________________________________________________________________________
block4c_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4b_add[0][0]                
__________________________________________________________________________________________________
block4c_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block4c_expand_conv[0][0]        
__________________________________________________________________________________________________
block4c_expand_activation (Acti (None, 8, 8, 480)    0           block4c_expand_bn[0][0]          
__________________________________________________________________________________________________
block4c_dwconv (DepthwiseConv2D (None, 8, 8, 480)    4320        block4c_expand_activation[0][0]  
__________________________________________________________________________________________________
block4c_bn (BatchNormalization) (None, 8, 8, 480)    1920        block4c_dwconv[0][0]             
__________________________________________________________________________________________________
block4c_activation (Activation) (None, 8, 8, 480)    0           block4c_bn[0][0]                 
__________________________________________________________________________________________________
block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         
__________________________________________________________________________________________________
block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         
__________________________________________________________________________________________________
block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          
__________________________________________________________________________________________________
block4c_se_excite (Multiply)    (None, 8, 8, 480)    0           block4c_activation[0][0]         
                                                                 block4c_se_expand[0][0]          
__________________________________________________________________________________________________
block4c_project_conv (Conv2D)   (None, 8, 8, 80)     38400       block4c_se_excite[0][0]          
__________________________________________________________________________________________________
block4c_project_bn (BatchNormal (None, 8, 8, 80)     320         block4c_project_conv[0][0]       
__________________________________________________________________________________________________
block4c_drop (Dropout)          (None, 8, 8, 80)     0           block4c_project_bn[0][0]         
__________________________________________________________________________________________________
block4c_add (Add)               (None, 8, 8, 80)     0           block4c_drop[0][0]               
                                                                 block4b_add[0][0]                
__________________________________________________________________________________________________
block5a_expand_conv (Conv2D)    (None, 8, 8, 480)    38400       block4c_add[0][0]                
__________________________________________________________________________________________________
block5a_expand_bn (BatchNormali (None, 8, 8, 480)    1920        block5a_expand_conv[0][0]        
__________________________________________________________________________________________________
block5a_expand_activation (Acti (None, 8, 8, 480)    0           block5a_expand_bn[0][0]          
__________________________________________________________________________________________________
block5a_dwconv (DepthwiseConv2D (None, 8, 8, 480)    12000       block5a_expand_activation[0][0]  
__________________________________________________________________________________________________
block5a_bn (BatchNormalization) (None, 8, 8, 480)    1920        block5a_dwconv[0][0]             
__________________________________________________________________________________________________
block5a_activation (Activation) (None, 8, 8, 480)    0           block5a_bn[0][0]                 
__________________________________________________________________________________________________
block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         
__________________________________________________________________________________________________
block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         
__________________________________________________________________________________________________
block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          
__________________________________________________________________________________________________
block5a_se_excite (Multiply)    (None, 8, 8, 480)    0           block5a_activation[0][0]         
                                                                 block5a_se_expand[0][0]          
__________________________________________________________________________________________________
block5a_project_conv (Conv2D)   (None, 8, 8, 112)    53760       block5a_se_excite[0][0]          
__________________________________________________________________________________________________
block5a_project_bn (BatchNormal (None, 8, 8, 112)    448         block5a_project_conv[0][0]       
__________________________________________________________________________________________________
block5b_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5a_project_bn[0][0]         
__________________________________________________________________________________________________
block5b_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5b_expand_conv[0][0]        
__________________________________________________________________________________________________
block5b_expand_activation (Acti (None, 8, 8, 672)    0           block5b_expand_bn[0][0]          
__________________________________________________________________________________________________
block5b_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5b_expand_activation[0][0]  
__________________________________________________________________________________________________
block5b_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5b_dwconv[0][0]             
__________________________________________________________________________________________________
block5b_activation (Activation) (None, 8, 8, 672)    0           block5b_bn[0][0]                 
__________________________________________________________________________________________________
block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         
__________________________________________________________________________________________________
block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         
__________________________________________________________________________________________________
block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          
__________________________________________________________________________________________________
block5b_se_excite (Multiply)    (None, 8, 8, 672)    0           block5b_activation[0][0]         
                                                                 block5b_se_expand[0][0]          
__________________________________________________________________________________________________
block5b_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5b_se_excite[0][0]          
__________________________________________________________________________________________________
block5b_project_bn (BatchNormal (None, 8, 8, 112)    448         block5b_project_conv[0][0]       
__________________________________________________________________________________________________
block5b_drop (Dropout)          (None, 8, 8, 112)    0           block5b_project_bn[0][0]         
__________________________________________________________________________________________________
block5b_add (Add)               (None, 8, 8, 112)    0           block5b_drop[0][0]               
                                                                 block5a_project_bn[0][0]         
__________________________________________________________________________________________________
block5c_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5b_add[0][0]                
__________________________________________________________________________________________________
block5c_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block5c_expand_conv[0][0]        
__________________________________________________________________________________________________
block5c_expand_activation (Acti (None, 8, 8, 672)    0           block5c_expand_bn[0][0]          
__________________________________________________________________________________________________
block5c_dwconv (DepthwiseConv2D (None, 8, 8, 672)    16800       block5c_expand_activation[0][0]  
__________________________________________________________________________________________________
block5c_bn (BatchNormalization) (None, 8, 8, 672)    2688        block5c_dwconv[0][0]             
__________________________________________________________________________________________________
block5c_activation (Activation) (None, 8, 8, 672)    0           block5c_bn[0][0]                 
__________________________________________________________________________________________________
block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         
__________________________________________________________________________________________________
block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         
__________________________________________________________________________________________________
block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          
__________________________________________________________________________________________________
block5c_se_excite (Multiply)    (None, 8, 8, 672)    0           block5c_activation[0][0]         
                                                                 block5c_se_expand[0][0]          
__________________________________________________________________________________________________
block5c_project_conv (Conv2D)   (None, 8, 8, 112)    75264       block5c_se_excite[0][0]          
__________________________________________________________________________________________________
block5c_project_bn (BatchNormal (None, 8, 8, 112)    448         block5c_project_conv[0][0]       
__________________________________________________________________________________________________
block5c_drop (Dropout)          (None, 8, 8, 112)    0           block5c_project_bn[0][0]         
__________________________________________________________________________________________________
block5c_add (Add)               (None, 8, 8, 112)    0           block5c_drop[0][0]               
                                                                 block5b_add[0][0]                
__________________________________________________________________________________________________
block6a_expand_conv (Conv2D)    (None, 8, 8, 672)    75264       block5c_add[0][0]                
__________________________________________________________________________________________________
block6a_expand_bn (BatchNormali (None, 8, 8, 672)    2688        block6a_expand_conv[0][0]        
__________________________________________________________________________________________________
block6a_expand_activation (Acti (None, 8, 8, 672)    0           block6a_expand_bn[0][0]          
__________________________________________________________________________________________________
block6a_dwconv_pad (ZeroPadding (None, 11, 11, 672)  0           block6a_expand_activation[0][0]  
__________________________________________________________________________________________________
block6a_dwconv (DepthwiseConv2D (None, 4, 4, 672)    16800       block6a_dwconv_pad[0][0]         
__________________________________________________________________________________________________
block6a_bn (BatchNormalization) (None, 4, 4, 672)    2688        block6a_dwconv[0][0]             
__________________________________________________________________________________________________
block6a_activation (Activation) (None, 4, 4, 672)    0           block6a_bn[0][0]                 
__________________________________________________________________________________________________
block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         
__________________________________________________________________________________________________
block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         
__________________________________________________________________________________________________
block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          
__________________________________________________________________________________________________
block6a_se_excite (Multiply)    (None, 4, 4, 672)    0           block6a_activation[0][0]         
                                                                 block6a_se_expand[0][0]          
__________________________________________________________________________________________________
block6a_project_conv (Conv2D)   (None, 4, 4, 192)    129024      block6a_se_excite[0][0]          
__________________________________________________________________________________________________
block6a_project_bn (BatchNormal (None, 4, 4, 192)    768         block6a_project_conv[0][0]       
__________________________________________________________________________________________________
block6b_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6a_project_bn[0][0]         
__________________________________________________________________________________________________
block6b_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6b_expand_conv[0][0]        
__________________________________________________________________________________________________
block6b_expand_activation (Acti (None, 4, 4, 1152)   0           block6b_expand_bn[0][0]          
__________________________________________________________________________________________________
block6b_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6b_expand_activation[0][0]  
__________________________________________________________________________________________________
block6b_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6b_dwconv[0][0]             
__________________________________________________________________________________________________
block6b_activation (Activation) (None, 4, 4, 1152)   0           block6b_bn[0][0]                 
__________________________________________________________________________________________________
block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         
__________________________________________________________________________________________________
block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         
__________________________________________________________________________________________________
block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          
__________________________________________________________________________________________________
block6b_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6b_activation[0][0]         
                                                                 block6b_se_expand[0][0]          
__________________________________________________________________________________________________
block6b_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6b_se_excite[0][0]          
__________________________________________________________________________________________________
block6b_project_bn (BatchNormal (None, 4, 4, 192)    768         block6b_project_conv[0][0]       
__________________________________________________________________________________________________
block6b_drop (Dropout)          (None, 4, 4, 192)    0           block6b_project_bn[0][0]         
__________________________________________________________________________________________________
block6b_add (Add)               (None, 4, 4, 192)    0           block6b_drop[0][0]               
                                                                 block6a_project_bn[0][0]         
__________________________________________________________________________________________________
block6c_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6b_add[0][0]                
__________________________________________________________________________________________________
block6c_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6c_expand_conv[0][0]        
__________________________________________________________________________________________________
block6c_expand_activation (Acti (None, 4, 4, 1152)   0           block6c_expand_bn[0][0]          
__________________________________________________________________________________________________
block6c_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6c_expand_activation[0][0]  
__________________________________________________________________________________________________
block6c_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6c_dwconv[0][0]             
__________________________________________________________________________________________________
block6c_activation (Activation) (None, 4, 4, 1152)   0           block6c_bn[0][0]                 
__________________________________________________________________________________________________
block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         
__________________________________________________________________________________________________
block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         
__________________________________________________________________________________________________
block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          
__________________________________________________________________________________________________
block6c_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6c_activation[0][0]         
                                                                 block6c_se_expand[0][0]          
__________________________________________________________________________________________________
block6c_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6c_se_excite[0][0]          
__________________________________________________________________________________________________
block6c_project_bn (BatchNormal (None, 4, 4, 192)    768         block6c_project_conv[0][0]       
__________________________________________________________________________________________________
block6c_drop (Dropout)          (None, 4, 4, 192)    0           block6c_project_bn[0][0]         
__________________________________________________________________________________________________
block6c_add (Add)               (None, 4, 4, 192)    0           block6c_drop[0][0]               
                                                                 block6b_add[0][0]                
__________________________________________________________________________________________________
block6d_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6c_add[0][0]                
__________________________________________________________________________________________________
block6d_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block6d_expand_conv[0][0]        
__________________________________________________________________________________________________
block6d_expand_activation (Acti (None, 4, 4, 1152)   0           block6d_expand_bn[0][0]          
__________________________________________________________________________________________________
block6d_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   28800       block6d_expand_activation[0][0]  
__________________________________________________________________________________________________
block6d_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block6d_dwconv[0][0]             
__________________________________________________________________________________________________
block6d_activation (Activation) (None, 4, 4, 1152)   0           block6d_bn[0][0]                 
__________________________________________________________________________________________________
block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         
__________________________________________________________________________________________________
block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         
__________________________________________________________________________________________________
block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         
__________________________________________________________________________________________________
block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          
__________________________________________________________________________________________________
block6d_se_excite (Multiply)    (None, 4, 4, 1152)   0           block6d_activation[0][0]         
                                                                 block6d_se_expand[0][0]          
__________________________________________________________________________________________________
block6d_project_conv (Conv2D)   (None, 4, 4, 192)    221184      block6d_se_excite[0][0]          
__________________________________________________________________________________________________
block6d_project_bn (BatchNormal (None, 4, 4, 192)    768         block6d_project_conv[0][0]       
__________________________________________________________________________________________________
block6d_drop (Dropout)          (None, 4, 4, 192)    0           block6d_project_bn[0][0]         
__________________________________________________________________________________________________
block6d_add (Add)               (None, 4, 4, 192)    0           block6d_drop[0][0]               
                                                                 block6c_add[0][0]                
__________________________________________________________________________________________________
block7a_expand_conv (Conv2D)    (None, 4, 4, 1152)   221184      block6d_add[0][0]                
__________________________________________________________________________________________________
block7a_expand_bn (BatchNormali (None, 4, 4, 1152)   4608        block7a_expand_conv[0][0]        
__________________________________________________________________________________________________
block7a_expand_activation (Acti (None, 4, 4, 1152)   0           block7a_expand_bn[0][0]          
__________________________________________________________________________________________________
block7a_dwconv (DepthwiseConv2D (None, 4, 4, 1152)   10368       block7a_expand_activation[0][0]  
__________________________________________________________________________________________________
block7a_bn (BatchNormalization) (None, 4, 4, 1152)   4608        block7a_dwconv[0][0]             
__________________________________________________________________________________________________
block7a_activation (Activation) (None, 4, 4, 1152)   0           block7a_bn[0][0]                 
__________________________________________________________________________________________________
block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         
__________________________________________________________________________________________________
block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         
__________________________________________________________________________________________________
block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         
__________________________________________________________________________________________________
block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          
__________________________________________________________________________________________________
block7a_se_excite (Multiply)    (None, 4, 4, 1152)   0           block7a_activation[0][0]         
                                                                 block7a_se_expand[0][0]          
__________________________________________________________________________________________________
block7a_project_conv (Conv2D)   (None, 4, 4, 320)    368640      block7a_se_excite[0][0]          
__________________________________________________________________________________________________
block7a_project_bn (BatchNormal (None, 4, 4, 320)    1280        block7a_project_conv[0][0]       
__________________________________________________________________________________________________/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  "The `lr` argument is deprecated, use `learning_rate` instead.")
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)

top_conv (Conv2D)               (None, 4, 4, 1280)   409600      block7a_project_bn[0][0]         
__________________________________________________________________________________________________
top_bn (BatchNormalization)     (None, 4, 4, 1280)   5120        top_conv[0][0]                   
__________________________________________________________________________________________________
top_activation (Activation)     (None, 4, 4, 1280)   0           top_bn[0][0]                     
__________________________________________________________________________________________________
pool5 (GlobalAveragePooling2D)  (None, 1280)         0           top_activation[0][0]             
__________________________________________________________________________________________________
Compound (Dense)                (None, 507)          649467      pool5[0][0]                      
==================================================================================================
Total params: 4,699,618
Trainable params: 4,657,591
Non-trainable params: 42,027
__________________________________________________________________________________________________
COMET INFO: Experiment is live on comet.ml https://www.comet.ml/michaelbornholdt/deepprofiler-lincs/64a6dffc92254f6cbf68d4a073018624

COMET WARNING: truncated string; too long: '{"checkpoints": "/local_group_storage/broad_data/michael/training/outputs/825_train/checkpoint/", "compressed_images": "/local_group_storage/broad_data/michael/training/outputs/compressed/images/", "config": "/local_group_storage/broad_data/michael/training/inputs/config/", "features": "/local_group_storage/broad_data/michael/training/outputs/825_train/features/", "images": "/local_group_storage/broad_data/michael/training/inputs/images/", "index": "/local_group_storage/broad_data/michael/training/inputs/metadata/823_index.csv", "intensities": "/local_group_storage/broad_data/michael/training/outputs/intensities/", "locations": "/local_group_storage/broad_data/michael/training/inputs/locations/", "logs": "/local_group_storage/broad_data/michael/training/outputs/825_train/logs/", "metadata": "/local_group_storage/broad_data/michael/training/inputs/metadata/", "results": "/local_group_storage/broad_data/michael/training/outputs/825_train/", "root": "/local_group_storage/broad_data/michael/training", "single_cell_sample": "/local_group_storage/broad_data/michael/training/outputs/823_sample/", "summaries": "/local_group_storage/broad_data/michael/training/outputs/825_train/summaries/"}'...
2021-08-26 00:46:34.250121: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-08-26 00:46:34.259551: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-08-26 00:46:34.317960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: A100-SXM4-40GB computeCapability: 8.0
coreClock: 1.41GHz coreCount: 108 deviceMemorySize: 39.59GiB deviceMemoryBandwidth: 1.41TiB/s
2021-08-26 00:46:34.318015: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-08-26 00:46:34.321433: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-08-26 00:46:34.321500: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-08-26 00:46:34.322664: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10
2021-08-26 00:46:34.322939: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10
2021-08-26 00:46:34.324056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11
2021-08-26 00:46:34.324984: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11
2021-08-26 00:46:34.325204: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-08-26 00:46:34.328420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0
2021-08-26 00:46:34.328451: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-08-26 00:46:34.859307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:
2021-08-26 00:46:34.859358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 
2021-08-26 00:46:34.859366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N 
2021-08-26 00:46:34.864252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 38423 MB memory) -> physical GPU (device: 0, name: A100-SXM4-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0)
2021-08-26 00:46:34,874 - WARNING - From /DeepProfiler/deepprofiler/learning/model.py:133: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

2021-08-26 00:46:35.365728: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3200140000 Hz
Validation data loaded : 1057 records of 1057
Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5
16711680/16705208 [==============================] - 0s 0us/step
Network initialized with pretrained ImageNet weights
2021-08-26 00:50:13,065 - WARNING - `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v1.py:1246: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.
  warnings.warn('`model.fit_generator` is deprecated and '
 || => Total single cells: 7710372
 || => Median # of images per class: 27
 || => Number of classes: 507
 || => Median # of cells per image: 251
 || => Approx. cells per epoch (with balanced sampling): 3435939
 || => Images sampled per worker: 16
 || => Cache data coverage: 0%
 || => Steps per epoch: 53686

Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.
Epoch 1/20
2021-08-26 00:50:24.346256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8
2021-08-26 00:50:24.955590: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8100
2021-08-26 00:50:25.576730: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11
2021-08-26 00:50:26.134882: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11
2021-08-26 00:50:26.473310: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
53686/53686 [==============================] - 17052s 317ms/step - batch: 26842.5000 - size: 64.0000 - loss: 3.5139 - acc: 0.2689 - top_5: 0.5298 - val_loss: 5.6034 - val_acc: 0.1212 - val_top_5: 0.2911 - lr: 0.0010

Epoch 00002: LearningRateScheduler reducing learning rate to 0.00125.
Epoch 2/20
53686/53686 [==============================] - 17328s 323ms/step - batch: 26842.5000 - size: 64.0000 - loss: 1.8293 - acc: 0.5476 - top_5: 0.8533 - val_loss: 7.3450 - val_acc: 0.1112 - val_top_5: 0.2678 - lr: 0.0012

Epoch 00003: LearningRateScheduler reducing learning rate to 0.0016666666666666668.
Epoch 3/20
53686/53686 [==============================] - 17166s 320ms/step - batch: 26842.5000 - size: 64.0000 - loss: 1.4260 - acc: 0.6483 - top_5: 0.9149 - val_loss: 5.1766 - val_acc: 0.2247 - val_top_5: 0.4656 - lr: 0.0017

Epoch 00004: LearningRateScheduler reducing learning rate to 0.0025.
Epoch 4/20
53686/53686 [==============================] - 17073s 318ms/step - batch: 26842.5000 - size: 64.0000 - loss: 1.2029 - acc: 0.7076 - top_5: 0.9429 - val_loss: 5.8342 - val_acc: 0.2116 - val_top_5: 0.4501 - lr: 0.0025

Epoch 00005: LearningRateScheduler reducing learning rate to 0.005.
Epoch 5/20
53686/53686 [==============================] - 16991s 316ms/step - batch: 26842.5000 - size: 64.0000 - loss: 1.0870 - acc: 0.7397 - top_5: 0.9559 - val_loss: 6.5864 - val_acc: 0.1509 - val_top_5: 0.3481 - lr: 0.0050

Epoch 00006: LearningRateScheduler reducing learning rate to 0.004267766952966369.
Epoch 6/20
53686/53686 [==============================] - 16950s 316ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.8525 - acc: 0.8096 - top_5: 0.9764 - val_loss: 6.3223 - val_acc: 0.2240 - val_top_5: 0.4626 - lr: 0.0043

Epoch 00007: LearningRateScheduler reducing learning rate to 0.003969463130731183.
Epoch 7/20
53686/53686 [==============================] - 17080s 318ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.7288 - acc: 0.8468 - top_5: 0.9846 - val_loss: 5.8713 - val_acc: 0.2729 - val_top_5: 0.5196 - lr: 0.0040

Epoch 00008: LearningRateScheduler reducing learning rate to 0.003634976249348867.
Epoch 8/20
53686/53686 [==============================] - 16921s 315ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.6386 - acc: 0.8739 - top_5: 0.9896 - val_loss: 6.4034 - val_acc: 0.2225 - val_top_5: 0.4525 - lr: 0.0036

Epoch 00009: LearningRateScheduler reducing learning rate to 0.0032725424859373687.
Epoch 9/20
53686/53686 [==============================] - 16635s 310ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.5626 - acc: 0.8969 - top_5: 0.9931 - val_loss: 6.1537 - val_acc: 0.2563 - val_top_5: 0.5101 - lr: 0.0033

Epoch 00010: LearningRateScheduler reducing learning rate to 0.0028910861626005773.
Epoch 10/20
53686/53686 [==============================] - 14152s 264ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.5032 - acc: 0.9146 - top_5: 0.9953 - val_loss: 6.1936 - val_acc: 0.2955 - val_top_5: 0.5494 - lr: 0.0029

Epoch 00011: LearningRateScheduler reducing learning rate to 0.0025.
Epoch 11/20
53686/53686 [==============================] - 7200s 134ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.4545 - acc: 0.9291 - top_5: 0.9968 - val_loss: 6.2358 - val_acc: 0.3069 - val_top_5: 0.5604 - lr: 0.0025

Epoch 00012: LearningRateScheduler reducing learning rate to 0.0021089138373994237.
Epoch 12/20
53686/53686 [==============================] - 7180s 134ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.4122 - acc: 0.9420 - top_5: 0.9979 - val_loss: 6.2492 - val_acc: 0.3055 - val_top_5: 0.5585 - lr: 0.0021

Epoch 00013: LearningRateScheduler reducing learning rate to 0.0017274575140626316.
Epoch 13/20
53686/53686 [==============================] - 7170s 134ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.3742 - acc: 0.9535 - top_5: 0.9987 - val_loss: 6.4114 - val_acc: 0.3054 - val_top_5: 0.5604 - lr: 0.0017

Epoch 00014: LearningRateScheduler reducing learning rate to 0.0013650237506511332.
Epoch 14/20
53686/53686 [==============================] - 7169s 134ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.3442 - acc: 0.9627 - top_5: 0.9992 - val_loss: 6.5503 - val_acc: 0.2902 - val_top_5: 0.5372 - lr: 0.0014

Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010305368692688174.
Epoch 15/20
53686/53686 [==============================] - 7174s 134ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.3212 - acc: 0.9698 - top_5: 0.9995 - val_loss: 6.3565 - val_acc: 0.3184 - val_top_5: 0.5734 - lr: 0.0010

Epoch 00016: LearningRateScheduler reducing learning rate to 0.0007322330470336313.
Epoch 16/20
53686/53686 [==============================] - 7294s 136ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.3032 - acc: 0.9751 - top_5: 0.9996 - val_loss: 6.5398 - val_acc: 0.3036 - val_top_5: 0.5534 - lr: 7.3223e-04

Epoch 00017: LearningRateScheduler reducing learning rate to 0.00047745751406263163.
Epoch 17/20
53686/53686 [==============================] - 7314s 136ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.2906 - acc: 0.9790 - top_5: 0.9997 - val_loss: 6.4165 - val_acc: 0.3270 - val_top_5: 0.5825 - lr: 4.7746e-04

Epoch 00018: LearningRateScheduler reducing learning rate to 0.00027248368952908055.
Epoch 18/20
53686/53686 [==============================] - 7338s 137ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.2820 - acc: 0.9817 - top_5: 0.9998 - val_loss: 6.4366 - val_acc: 0.3268 - val_top_5: 0.5841 - lr: 2.7248e-04

Epoch 00019: LearningRateScheduler reducing learning rate to 0.00012235870926211617.
Epoch 19/20
53686/53686 [==============================] - 7335s 137ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.2774 - acc: 0.9830 - top_5: 0.9998 - val_loss: 6.4508 - val_acc: 0.3276 - val_top_5: 0.5846 - lr: 1.2236e-04

Epoch 00020: LearningRateScheduler reducing learning rate to 3.077914851215585e-05.
Epoch 20/20
53686/53686 [==============================] - 7332s 137ms/step - batch: 26842.5000 - size: 64.0000 - loss: 0.2747 - acc: 0.9840 - top_5: 0.9998 - val_loss: 6.4488 - val_acc: 0.3277 - val_top_5: 0.5848 - lr: 3.0779e-05
Complete! Closing session. All set.
COMET INFO: ---------------------------
COMET INFO: Comet.ml Experiment Summary
COMET INFO: ---------------------------
